(lhz-torch-2.0) lhz@csgpu-SYS-4029GP-TRT:~/code/LAMDA-PILOT$ python main.py --config=exps/l2p_self_training.json
2024-01-13 16:37:28,244 [trainer.py] => config: exps/l2p_self_training.json
2024-01-13 16:37:28,244 [trainer.py] => prefix:  
2024-01-13 16:37:28,244 [trainer.py] => dataset: cifar224
2024-01-13 16:37:28,244 [trainer.py] => memory_size: 0
2024-01-13 16:37:28,244 [trainer.py] => memory_per_class: 0
2024-01-13 16:37:28,244 [trainer.py] => fixed_memory: False
2024-01-13 16:37:28,244 [trainer.py] => shuffle: True
2024-01-13 16:37:28,244 [trainer.py] => init_cls: 10
2024-01-13 16:37:28,244 [trainer.py] => increment: 10
2024-01-13 16:37:28,244 [trainer.py] => model_name: l2p_self_training
2024-01-13 16:37:28,244 [trainer.py] => backbone_type: vit_base_patch16_224_l2p
2024-01-13 16:37:28,244 [trainer.py] => get_original_backbone: True
2024-01-13 16:37:28,244 [trainer.py] => device: [device(type='cuda', index=5)]
2024-01-13 16:37:28,244 [trainer.py] => seed: 1993
2024-01-13 16:37:28,244 [trainer.py] => tuned_epoch: 5
2024-01-13 16:37:28,244 [trainer.py] => init_lr: 0.001875
2024-01-13 16:37:28,244 [trainer.py] => batch_size: 16
2024-01-13 16:37:28,244 [trainer.py] => weight_decay: 0
2024-01-13 16:37:28,244 [trainer.py] => min_lr: 1e-05
2024-01-13 16:37:28,244 [trainer.py] => optimizer: adam
2024-01-13 16:37:28,245 [trainer.py] => scheduler: constant
2024-01-13 16:37:28,245 [trainer.py] => reinit_optimizer: True
2024-01-13 16:37:28,245 [trainer.py] => global_pool: token
2024-01-13 16:37:28,245 [trainer.py] => head_type: prompt
2024-01-13 16:37:28,245 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2024-01-13 16:37:28,245 [trainer.py] => pretrained: True
2024-01-13 16:37:28,245 [trainer.py] => drop: 0.0
2024-01-13 16:37:28,245 [trainer.py] => drop_path: 0.0
2024-01-13 16:37:28,245 [trainer.py] => prompt_pool: True
2024-01-13 16:37:28,245 [trainer.py] => pool_size: 10
2024-01-13 16:37:28,245 [trainer.py] => length: 5
2024-01-13 16:37:28,245 [trainer.py] => top_k: 5
2024-01-13 16:37:28,245 [trainer.py] => initializer: uniform
2024-01-13 16:37:28,245 [trainer.py] => prompt_key: True
2024-01-13 16:37:28,245 [trainer.py] => prompt_key_init: uniform
2024-01-13 16:37:28,245 [trainer.py] => use_prompt_mask: False
2024-01-13 16:37:28,245 [trainer.py] => shared_prompt_pool: False
2024-01-13 16:37:28,245 [trainer.py] => shared_prompt_key: False
2024-01-13 16:37:28,245 [trainer.py] => batchwise_prompt: True
2024-01-13 16:37:28,245 [trainer.py] => embedding_key: cls
2024-01-13 16:37:28,245 [trainer.py] => predefined_key: 
2024-01-13 16:37:28,245 [trainer.py] => pull_constraint: True
2024-01-13 16:37:28,245 [trainer.py] => pull_constraint_coeff: 0.1
2024-01-13 16:37:28,245 [trainer.py] => semi_supervised_mode: True
2024-01-13 16:37:28,245 [trainer.py] => labeled_ratio: 0.05
2024-01-13 16:37:28,245 [trainer.py] => unlabeled_data_distribution_mode: previous_oot
2024-01-13 16:37:28,245 [trainer.py] => confidence_threshold: 0.9
2024-01-13 16:37:28,245 [trainer.py] => max_self_training_iteration: 3
Files already downloaded and verified
Files already downloaded and verified
2024-01-13 16:37:30,368 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-01-13 16:37:32,006 [vision_transformer_l2p.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2024-01-13 16:37:32,007 [vision_transformer_l2p.py] => Position embedding grid-size from [14, 14] to (14, 14)
2024-01-13 16:37:34,365 [l2p_self_training.py] => 85,940,836 model total parameters.
2024-01-13 16:37:34,366 [l2p_self_training.py] => 122,980 model training parameters.
2024-01-13 16:37:34,366 [l2p_self_training.py] => prompt.prompt: 38400
2024-01-13 16:37:34,366 [l2p_self_training.py] => prompt.prompt_key: 7680
2024-01-13 16:37:34,366 [l2p_self_training.py] => head.weight: 76800
2024-01-13 16:37:34,366 [l2p_self_training.py] => head.bias: 100
2024-01-13 16:37:34,367 [trainer.py] => All params: 171816392
2024-01-13 16:37:34,368 [trainer.py] => Trainable params: 122980
2024-01-13 16:37:34,368 [l2p_self_training.py] => Learning on 0-10
2024-01-13 16:37:34,998 [l2p_self_training.py] => train dataset length: 250
Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50: 100%|███████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.75s/it]
2024-01-13 16:37:53,729 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50
2024-01-13 16:37:53,732 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:38:08,207 [l2p_self_training.py] => 1038 unlabeled samples will be pseudo labeled
2024-01-13 16:38:08,208 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:38:08,208 [toolkit.py] => Pseudo Accuracy: 0.9788053949903661
2024-01-13 16:38:08,213 [l2p_self_training.py] => train dataset length: 1288
Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70: 100%|███████████████████████████████████████████████████| 5/5 [01:04<00:00, 12.92s/it]
2024-01-13 16:39:12,821 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70
2024-01-13 16:39:12,825 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:39:27,432 [l2p_self_training.py] => 1668 unlabeled samples will be pseudo labeled
2024-01-13 16:39:27,432 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:39:27,433 [toolkit.py] => Pseudo Accuracy: 0.9508393285371702
2024-01-13 16:39:27,438 [l2p_self_training.py] => train dataset length: 1918
Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70: 100%|███████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.71s/it]
2024-01-13 16:41:00,988 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70
2024-01-13 16:41:00,991 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:41:15,688 [l2p_self_training.py] => 1679 unlabeled samples will be pseudo labeled
2024-01-13 16:41:15,688 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:41:15,689 [toolkit.py] => Pseudo Accuracy: 0.9535437760571769
2024-01-13 16:41:21,731 [trainer.py] => No NME accuracy.
2024-01-13 16:41:21,731 [trainer.py] => CNN: {'total': 90.7, '00-09': 90.7, 'old': 0, 'new': 90.7}
2024-01-13 16:41:21,731 [trainer.py] => CNN top1 curve: [90.7]
2024-01-13 16:41:21,731 [trainer.py] => CNN top5 curve: [99.2]

Average Accuracy (CNN): 90.7
2024-01-13 16:41:21,731 [trainer.py] => Average Accuracy (CNN): 90.7 

2024-01-13 16:41:21,733 [trainer.py] => All params: 171816392
2024-01-13 16:41:21,734 [trainer.py] => Trainable params: 122980
2024-01-13 16:41:21,734 [l2p_self_training.py] => Learning on 10-20
2024-01-13 16:41:21,788 [l2p_self_training.py] => train dataset length: 250
Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95: 100%|██████████████████████████████████████████████████| 5/5 [00:24<00:00,  4.96s/it]
2024-01-13 16:41:46,570 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95
2024-01-13 16:41:46,572 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:42:02,705 [l2p_self_training.py] => 1541 unlabeled samples will be pseudo labeled
2024-01-13 16:42:02,706 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:42:02,707 [toolkit.py] => Pseudo Accuracy: 0.9565217391304348
2024-01-13 16:42:02,710 [l2p_self_training.py] => train dataset length: 1791
Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60: 100%|███████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.73s/it]
2024-01-13 16:43:36,344 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60
2024-01-13 16:43:36,348 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:43:52,565 [l2p_self_training.py] => 1794 unlabeled samples will be pseudo labeled
2024-01-13 16:43:52,565 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:43:52,566 [toolkit.py] => Pseudo Accuracy: 0.9308807134894092
2024-01-13 16:43:52,569 [l2p_self_training.py] => train dataset length: 2044
Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50: 100%|███████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.01s/it]
2024-01-13 16:45:37,614 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50
2024-01-13 16:45:37,617 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:45:53,817 [l2p_self_training.py] => 1922 unlabeled samples will be pseudo labeled
2024-01-13 16:45:53,818 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:45:53,818 [toolkit.py] => Pseudo Accuracy: 0.9167533818938606
2024-01-13 16:46:05,689 [trainer.py] => No NME accuracy.
2024-01-13 16:46:05,689 [trainer.py] => CNN: {'total': 48.5, '00-09': 1.9, '10-19': 95.1, 'old': 1.9, 'new': 95.1}
2024-01-13 16:46:05,689 [trainer.py] => CNN top1 curve: [90.7, 48.5]
2024-01-13 16:46:05,689 [trainer.py] => CNN top5 curve: [99.2, 54.8]

Average Accuracy (CNN): 69.6
2024-01-13 16:46:05,689 [trainer.py] => Average Accuracy (CNN): 69.6 

2024-01-13 16:46:05,690 [trainer.py] => All params: 171816392
2024-01-13 16:46:05,691 [trainer.py] => Trainable params: 122980
2024-01-13 16:46:05,691 [l2p_self_training.py] => Learning on 20-30
2024-01-13 16:46:05,727 [l2p_self_training.py] => train dataset length: 250
Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00: 100%|██████████████████████████████████████████████████| 5/5 [00:30<00:00,  6.14s/it]
2024-01-13 16:46:36,449 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00
2024-01-13 16:46:36,452 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:46:54,140 [l2p_self_training.py] => 1838 unlabeled samples will be pseudo labeled
2024-01-13 16:46:54,141 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:46:54,141 [toolkit.py] => Pseudo Accuracy: 0.9613710554951034
2024-01-13 16:46:54,146 [l2p_self_training.py] => train dataset length: 2088
Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43: 100%|██████████████████████████████████████████████████| 5/5 [01:53<00:00, 22.62s/it]
2024-01-13 16:48:47,243 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43
2024-01-13 16:48:47,245 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:49:04,874 [l2p_self_training.py] => 2263 unlabeled samples will be pseudo labeled
2024-01-13 16:49:04,874 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:49:04,875 [toolkit.py] => Pseudo Accuracy: 0.8811312417145383
2024-01-13 16:49:04,879 [l2p_self_training.py] => train dataset length: 2513
Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97: 100%|██████████████████████████████████████████████████| 5/5 [02:12<00:00, 26.42s/it]
2024-01-13 16:51:16,961 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97
2024-01-13 16:51:16,963 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:51:34,567 [l2p_self_training.py] => 2305 unlabeled samples will be pseudo labeled
2024-01-13 16:51:34,567 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:51:34,568 [toolkit.py] => Pseudo Accuracy: 0.879826464208243
2024-01-13 16:51:52,203 [trainer.py] => No NME accuracy.
2024-01-13 16:51:52,203 [trainer.py] => CNN: {'total': 31.97, '00-09': 0.0, '10-19': 0.5, '20-29': 95.4, 'old': 0.25, 'new': 95.4}
2024-01-13 16:51:52,203 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97]
2024-01-13 16:51:52,203 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0]

Average Accuracy (CNN): 57.056666666666665
2024-01-13 16:51:52,203 [trainer.py] => Average Accuracy (CNN): 57.056666666666665 

2024-01-13 16:51:52,205 [trainer.py] => All params: 171816392
2024-01-13 16:51:52,206 [trainer.py] => Trainable params: 122980
2024-01-13 16:51:52,206 [l2p_self_training.py] => Learning on 30-40
2024-01-13 16:51:52,248 [l2p_self_training.py] => train dataset length: 250
Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18: 100%|██████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.21s/it]
2024-01-13 16:52:28,294 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18
2024-01-13 16:52:28,297 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:52:47,402 [l2p_self_training.py] => 1712 unlabeled samples will be pseudo labeled
2024-01-13 16:52:47,402 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:52:47,403 [toolkit.py] => Pseudo Accuracy: 0.927570093457944
2024-01-13 16:52:47,408 [l2p_self_training.py] => train dataset length: 1962
Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70: 100%|██████████████████████████████████████████████████| 5/5 [01:52<00:00, 22.58s/it]
2024-01-13 16:54:40,285 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70
2024-01-13 16:54:40,288 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:54:59,314 [l2p_self_training.py] => 2365 unlabeled samples will be pseudo labeled
2024-01-13 16:54:59,314 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:54:59,315 [toolkit.py] => Pseudo Accuracy: 0.8228329809725159
2024-01-13 16:54:59,319 [l2p_self_training.py] => train dataset length: 2615
Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30: 100%|██████████████████████████████████████████████████| 5/5 [02:21<00:00, 28.37s/it]
2024-01-13 16:57:21,159 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30
2024-01-13 16:57:21,161 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:57:40,154 [l2p_self_training.py] => 2407 unlabeled samples will be pseudo labeled
2024-01-13 16:57:40,155 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:57:40,155 [toolkit.py] => Pseudo Accuracy: 0.7947652679684254
2024-01-13 16:58:03,483 [trainer.py] => No NME accuracy.
2024-01-13 16:58:03,483 [trainer.py] => CNN: {'total': 32.3, '00-09': 0.0, '10-19': 0.0, '20-29': 39.6, '30-39': 89.6, 'old': 13.2, 'new': 89.6}
2024-01-13 16:58:03,483 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3]
2024-01-13 16:58:03,484 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83]

Average Accuracy (CNN): 50.86749999999999
2024-01-13 16:58:03,484 [trainer.py] => Average Accuracy (CNN): 50.86749999999999 

2024-01-13 16:58:03,485 [trainer.py] => All params: 171816392
2024-01-13 16:58:03,487 [trainer.py] => Trainable params: 122980
2024-01-13 16:58:03,487 [l2p_self_training.py] => Learning on 40-50
2024-01-13 16:58:03,540 [l2p_self_training.py] => train dataset length: 250
Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.085, Train_accy 92.80, Test_accy 27.60: 100%|██████████████████████████████████████████████████| 5/5 [00:42<00:00,  8.43s/it]
2024-01-13 16:58:45,690 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.085, Train_accy 92.80, Test_accy 27.60
2024-01-13 16:58:45,693 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:59:06,164 [l2p_self_training.py] => 1937 unlabeled samples will be pseudo labeled
2024-01-13 16:59:06,164 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:59:06,164 [toolkit.py] => Pseudo Accuracy: 0.9210118740320082
2024-01-13 16:59:06,168 [l2p_self_training.py] => train dataset length: 2187
Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.146, Train_accy 94.60, Test_accy 31.74: 100%|██████████████████████████████████████████████████| 5/5 [02:08<00:00, 25.68s/it]
2024-01-13 17:01:14,593 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.146, Train_accy 94.60, Test_accy 31.74
2024-01-13 17:01:14,597 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:01:35,109 [l2p_self_training.py] => 2615 unlabeled samples will be pseudo labeled
2024-01-13 17:01:35,109 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:01:35,110 [toolkit.py] => Pseudo Accuracy: 0.8409177820267686
2024-01-13 17:01:35,115 [l2p_self_training.py] => train dataset length: 2865
Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.077, Train_accy 92.71, Test_accy 29.54: 100%|██████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.73s/it]
2024-01-13 17:04:13,761 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.077, Train_accy 92.71, Test_accy 29.54
2024-01-13 17:04:13,765 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:04:34,289 [l2p_self_training.py] => 2697 unlabeled samples will be pseudo labeled
2024-01-13 17:04:34,289 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:04:34,290 [toolkit.py] => Pseudo Accuracy: 0.8075639599555061
2024-01-13 17:05:03,362 [trainer.py] => No NME accuracy.
2024-01-13 17:05:03,362 [trainer.py] => CNN: {'total': 29.54, '00-09': 0.0, '10-19': 0.0, '20-29': 17.0, '30-39': 33.0, '40-49': 97.7, 'old': 12.5, 'new': 97.7}
2024-01-13 17:05:03,362 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54]
2024-01-13 17:05:03,362 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86]

Average Accuracy (CNN): 46.60199999999999
2024-01-13 17:05:03,363 [trainer.py] => Average Accuracy (CNN): 46.60199999999999 

2024-01-13 17:05:03,364 [trainer.py] => All params: 171816392
2024-01-13 17:05:03,365 [trainer.py] => Trainable params: 122980
2024-01-13 17:05:03,365 [l2p_self_training.py] => Learning on 50-60
2024-01-13 17:05:03,417 [l2p_self_training.py] => train dataset length: 250
Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.036, Train_accy 90.00, Test_accy 28.17: 100%|██████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.60s/it]
2024-01-13 17:05:51,416 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.036, Train_accy 90.00, Test_accy 28.17
2024-01-13 17:05:51,418 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:06:13,243 [l2p_self_training.py] => 1795 unlabeled samples will be pseudo labeled
2024-01-13 17:06:13,243 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:06:13,244 [toolkit.py] => Pseudo Accuracy: 0.9175487465181058
2024-01-13 17:06:13,249 [l2p_self_training.py] => train dataset length: 2045
Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.81, Test_accy 29.85: 100%|██████████████████████████████████████████████████| 5/5 [02:07<00:00, 25.53s/it]
2024-01-13 17:08:20,897 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.81, Test_accy 29.85
2024-01-13 17:08:20,900 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:08:42,750 [l2p_self_training.py] => 2532 unlabeled samples will be pseudo labeled
2024-01-13 17:08:42,751 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:08:42,752 [toolkit.py] => Pseudo Accuracy: 0.8135860979462876
2024-01-13 17:08:42,758 [l2p_self_training.py] => train dataset length: 2782
Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.066, Train_accy 92.42, Test_accy 29.10: 100%|██████████████████████████████████████████████████| 5/5 [02:40<00:00, 32.18s/it]
2024-01-13 17:11:23,641 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.066, Train_accy 92.42, Test_accy 29.10
2024-01-13 17:11:23,643 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:11:45,486 [l2p_self_training.py] => 2697 unlabeled samples will be pseudo labeled
2024-01-13 17:11:45,486 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:11:45,487 [toolkit.py] => Pseudo Accuracy: 0.7701149425287356
2024-01-13 17:12:20,253 [trainer.py] => No NME accuracy.
2024-01-13 17:12:20,253 [trainer.py] => CNN: {'total': 29.1, '00-09': 0.0, '10-19': 0.0, '20-29': 10.1, '30-39': 25.7, '40-49': 43.9, '50-59': 94.9, 'old': 15.94, 'new': 94.9}
2024-01-13 17:12:20,254 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1]
2024-01-13 17:12:20,254 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12]

Average Accuracy (CNN): 43.684999999999995
2024-01-13 17:12:20,254 [trainer.py] => Average Accuracy (CNN): 43.684999999999995 

2024-01-13 17:12:20,257 [trainer.py] => All params: 171816392
2024-01-13 17:12:20,260 [trainer.py] => Trainable params: 122980
2024-01-13 17:12:20,260 [l2p_self_training.py] => Learning on 60-70
2024-01-13 17:12:20,328 [l2p_self_training.py] => train dataset length: 250
Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.102, Train_accy 93.60, Test_accy 27.13: 100%|██████████████████████████████████████████████████| 5/5 [00:53<00:00, 10.65s/it]
2024-01-13 17:13:13,568 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.102, Train_accy 93.60, Test_accy 27.13
2024-01-13 17:13:13,571 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:13:36,864 [l2p_self_training.py] => 2074 unlabeled samples will be pseudo labeled
2024-01-13 17:13:36,864 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:13:36,865 [toolkit.py] => Pseudo Accuracy: 0.9387656702025072
2024-01-13 17:13:36,869 [l2p_self_training.py] => train dataset length: 2324
Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.93, Test_accy 30.16: 100%|██████████████████████████████████████████████████| 5/5 [02:26<00:00, 29.22s/it]
2024-01-13 17:16:02,954 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.93, Test_accy 30.16
2024-01-13 17:16:02,956 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:16:26,266 [l2p_self_training.py] => 2866 unlabeled samples will be pseudo labeled
2024-01-13 17:16:26,266 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:16:26,267 [toolkit.py] => Pseudo Accuracy: 0.8210048848569435
2024-01-13 17:16:26,274 [l2p_self_training.py] => train dataset length: 3116
Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.063, Train_accy 92.23, Test_accy 30.51: 100%|██████████████████████████████████████████████████| 5/5 [03:02<00:00, 36.43s/it]
2024-01-13 17:19:28,407 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.063, Train_accy 92.23, Test_accy 30.51
2024-01-13 17:19:28,409 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:19:51,817 [l2p_self_training.py] => 2931 unlabeled samples will be pseudo labeled
2024-01-13 17:19:51,817 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:19:51,818 [toolkit.py] => Pseudo Accuracy: 0.7922210849539406
2024-01-13 17:20:32,569 [trainer.py] => No NME accuracy.
2024-01-13 17:20:32,570 [trainer.py] => CNN: {'total': 30.51, '00-09': 0.0, '10-19': 0.0, '20-29': 16.4, '30-39': 22.9, '40-49': 31.0, '50-59': 45.1, '60-69': 98.2, 'old': 19.23, 'new': 98.2}
2024-01-13 17:20:32,570 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51]
2024-01-13 17:20:32,570 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73]

Average Accuracy (CNN): 41.802857142857135
2024-01-13 17:20:32,570 [trainer.py] => Average Accuracy (CNN): 41.802857142857135 

2024-01-13 17:20:32,572 [trainer.py] => All params: 171816392
2024-01-13 17:20:32,573 [trainer.py] => Trainable params: 122980
2024-01-13 17:20:32,573 [l2p_self_training.py] => Learning on 70-80
2024-01-13 17:20:32,635 [l2p_self_training.py] => train dataset length: 250
Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.019, Train_accy 90.80, Test_accy 24.54: 100%|██████████████████████████████████████████████████| 5/5 [00:59<00:00, 11.87s/it]
2024-01-13 17:21:32,003 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.019, Train_accy 90.80, Test_accy 24.54
2024-01-13 17:21:32,007 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:21:56,900 [l2p_self_training.py] => 1785 unlabeled samples will be pseudo labeled
2024-01-13 17:21:56,900 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:21:56,901 [toolkit.py] => Pseudo Accuracy: 0.8795518207282913
2024-01-13 17:21:56,905 [l2p_self_training.py] => train dataset length: 2035
Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.180, Train_accy 95.18, Test_accy 27.59: 100%|██████████████████████████████████████████████████| 5/5 [02:19<00:00, 27.94s/it]
2024-01-13 17:24:16,618 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.180, Train_accy 95.18, Test_accy 27.59
2024-01-13 17:24:16,620 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:24:41,605 [l2p_self_training.py] => 2886 unlabeled samples will be pseudo labeled
2024-01-13 17:24:41,605 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:24:41,606 [toolkit.py] => Pseudo Accuracy: 0.7366597366597366
2024-01-13 17:24:41,611 [l2p_self_training.py] => train dataset length: 3136
Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.039, Train_accy 91.04, Test_accy 27.49: 100%|██████████████████████████████████████████████████| 5/5 [03:10<00:00, 38.09s/it]
2024-01-13 17:27:52,075 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.039, Train_accy 91.04, Test_accy 27.49
2024-01-13 17:27:52,077 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:28:17,458 [l2p_self_training.py] => 3016 unlabeled samples will be pseudo labeled
2024-01-13 17:28:17,459 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:28:17,459 [toolkit.py] => Pseudo Accuracy: 0.7078912466843501
2024-01-13 17:29:04,373 [trainer.py] => No NME accuracy.
2024-01-13 17:29:04,373 [trainer.py] => CNN: {'total': 27.49, '00-09': 0.0, '10-19': 0.0, '20-29': 15.9, '30-39': 24.4, '40-49': 20.8, '50-59': 6.4, '60-69': 59.7, '70-79': 92.7, 'old': 18.17, 'new': 92.7}
2024-01-13 17:29:04,374 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49]
2024-01-13 17:29:04,374 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22]

Average Accuracy (CNN): 40.013749999999995
2024-01-13 17:29:04,374 [trainer.py] => Average Accuracy (CNN): 40.013749999999995 

2024-01-13 17:29:04,375 [trainer.py] => All params: 171816392
2024-01-13 17:29:04,376 [trainer.py] => Trainable params: 122980
2024-01-13 17:29:04,376 [l2p_self_training.py] => Learning on 80-90
2024-01-13 17:29:04,532 [l2p_self_training.py] => train dataset length: 250
Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.042, Train_accy 90.40, Test_accy 22.86: 100%|██████████████████████████████████████████████████| 5/5 [01:05<00:00, 13.16s/it]
2024-01-13 17:30:10,323 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.042, Train_accy 90.40, Test_accy 22.86
2024-01-13 17:30:10,325 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:30:36,707 [l2p_self_training.py] => 1985 unlabeled samples will be pseudo labeled
2024-01-13 17:30:36,707 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:30:36,708 [toolkit.py] => Pseudo Accuracy: 0.8937027707808565
2024-01-13 17:30:36,715 [l2p_self_training.py] => train dataset length: 2235
Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.116, Train_accy 94.18, Test_accy 24.93: 100%|██████████████████████████████████████████████████| 5/5 [02:34<00:00, 30.81s/it]
2024-01-13 17:33:10,742 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.116, Train_accy 94.18, Test_accy 24.93
2024-01-13 17:33:10,744 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:33:37,001 [l2p_self_training.py] => 2888 unlabeled samples will be pseudo labeled
2024-01-13 17:33:37,001 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:33:37,002 [toolkit.py] => Pseudo Accuracy: 0.7725069252077562
2024-01-13 17:33:37,008 [l2p_self_training.py] => train dataset length: 3138
Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.27, Test_accy 23.64: 100%|██████████████████████████████████████████████████| 5/5 [03:14<00:00, 38.85s/it]
2024-01-13 17:36:51,264 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.27, Test_accy 23.64
2024-01-13 17:36:51,268 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:37:17,441 [l2p_self_training.py] => 3082 unlabeled samples will be pseudo labeled
2024-01-13 17:37:17,442 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:37:17,443 [toolkit.py] => Pseudo Accuracy: 0.7196625567813109
2024-01-13 17:38:09,611 [trainer.py] => No NME accuracy.
2024-01-13 17:38:09,612 [trainer.py] => CNN: {'total': 23.64, '00-09': 0.0, '10-19': 0.0, '20-29': 10.3, '30-39': 20.5, '40-49': 11.8, '50-59': 2.0, '60-69': 36.6, '70-79': 35.3, '80-89': 96.3, 'old': 14.56, 'new': 96.3}
2024-01-13 17:38:09,612 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49, 23.64]
2024-01-13 17:38:09,612 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22, 30.0]

Average Accuracy (CNN): 38.194444444444436
2024-01-13 17:38:09,612 [trainer.py] => Average Accuracy (CNN): 38.194444444444436 

2024-01-13 17:38:09,614 [trainer.py] => All params: 171816392
2024-01-13 17:38:09,615 [trainer.py] => Trainable params: 122980
2024-01-13 17:38:09,615 [l2p_self_training.py] => Learning on 90-100
2024-01-13 17:38:09,766 [l2p_self_training.py] => train dataset length: 250
Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.020, Train_accy 90.00, Test_accy 23.96: 100%|██████████████████████████████████████████████████| 5/5 [01:10<00:00, 14.09s/it]
2024-01-13 17:39:20,225 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.020, Train_accy 90.00, Test_accy 23.96
2024-01-13 17:39:20,229 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:39:47,896 [l2p_self_training.py] => 1943 unlabeled samples will be pseudo labeled
2024-01-13 17:39:47,896 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:39:47,897 [toolkit.py] => Pseudo Accuracy: 0.9186824498198661
2024-01-13 17:39:47,906 [l2p_self_training.py] => train dataset length: 2193
Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.16, Test_accy 25.88: 100%|██████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.75s/it]
2024-01-13 17:42:26,652 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.16, Test_accy 25.88
2024-01-13 17:42:26,655 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:42:54,299 [l2p_self_training.py] => 2832 unlabeled samples will be pseudo labeled
2024-01-13 17:42:54,299 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:42:54,300 [toolkit.py] => Pseudo Accuracy: 0.7874293785310734
2024-01-13 17:42:54,305 [l2p_self_training.py] => train dataset length: 3082
Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.30, Test_accy 25.50: 100%|██████████████████████████████████████████████████| 5/5 [03:17<00:00, 39.48s/it]
2024-01-13 17:46:11,731 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.30, Test_accy 25.50
2024-01-13 17:46:11,733 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:46:39,313 [l2p_self_training.py] => 3086 unlabeled samples will be pseudo labeled
2024-01-13 17:46:39,314 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:46:39,315 [toolkit.py] => Pseudo Accuracy: 0.7300712896953986
2024-01-13 17:47:37,385 [trainer.py] => No NME accuracy.
2024-01-13 17:47:37,385 [trainer.py] => CNN: {'total': 25.5, '00-09': 0.0, '10-19': 0.0, '20-29': 13.6, '30-39': 23.2, '40-49': 12.6, '50-59': 1.9, '60-69': 25.5, '70-79': 9.5, '80-89': 73.7, '90-99': 95.0, 'old': 17.78, 'new': 95.0}
2024-01-13 17:47:37,385 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49, 23.64, 25.5]
2024-01-13 17:47:37,385 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22, 30.0, 30.6]

Average Accuracy (CNN): 36.925
2024-01-13 17:47:37,385 [trainer.py] => Average Accuracy (CNN): 36.925 (lhz-torch-2.0) lhz@csgpu-SYS-4029GP-TRT:~/code/LAMDA-PILOT$ python main.py --config=exps/l2p_self_training.json
2024-01-13 16:37:28,244 [trainer.py] => config: exps/l2p_self_training.json
2024-01-13 16:37:28,244 [trainer.py] => prefix:  
2024-01-13 16:37:28,244 [trainer.py] => dataset: cifar224
2024-01-13 16:37:28,244 [trainer.py] => memory_size: 0
2024-01-13 16:37:28,244 [trainer.py] => memory_per_class: 0
2024-01-13 16:37:28,244 [trainer.py] => fixed_memory: False
2024-01-13 16:37:28,244 [trainer.py] => shuffle: True
2024-01-13 16:37:28,244 [trainer.py] => init_cls: 10
2024-01-13 16:37:28,244 [trainer.py] => increment: 10
2024-01-13 16:37:28,244 [trainer.py] => model_name: l2p_self_training
2024-01-13 16:37:28,244 [trainer.py] => backbone_type: vit_base_patch16_224_l2p
2024-01-13 16:37:28,244 [trainer.py] => get_original_backbone: True
2024-01-13 16:37:28,244 [trainer.py] => device: [device(type='cuda', index=5)]
2024-01-13 16:37:28,244 [trainer.py] => seed: 1993
2024-01-13 16:37:28,244 [trainer.py] => tuned_epoch: 5
2024-01-13 16:37:28,244 [trainer.py] => init_lr: 0.001875
2024-01-13 16:37:28,244 [trainer.py] => batch_size: 16
2024-01-13 16:37:28,244 [trainer.py] => weight_decay: 0
2024-01-13 16:37:28,244 [trainer.py] => min_lr: 1e-05
2024-01-13 16:37:28,244 [trainer.py] => optimizer: adam
2024-01-13 16:37:28,245 [trainer.py] => scheduler: constant
2024-01-13 16:37:28,245 [trainer.py] => reinit_optimizer: True
2024-01-13 16:37:28,245 [trainer.py] => global_pool: token
2024-01-13 16:37:28,245 [trainer.py] => head_type: prompt
2024-01-13 16:37:28,245 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2024-01-13 16:37:28,245 [trainer.py] => pretrained: True
2024-01-13 16:37:28,245 [trainer.py] => drop: 0.0
2024-01-13 16:37:28,245 [trainer.py] => drop_path: 0.0
2024-01-13 16:37:28,245 [trainer.py] => prompt_pool: True
2024-01-13 16:37:28,245 [trainer.py] => pool_size: 10
2024-01-13 16:37:28,245 [trainer.py] => length: 5
2024-01-13 16:37:28,245 [trainer.py] => top_k: 5
2024-01-13 16:37:28,245 [trainer.py] => initializer: uniform
2024-01-13 16:37:28,245 [trainer.py] => prompt_key: True
2024-01-13 16:37:28,245 [trainer.py] => prompt_key_init: uniform
2024-01-13 16:37:28,245 [trainer.py] => use_prompt_mask: False
2024-01-13 16:37:28,245 [trainer.py] => shared_prompt_pool: False
2024-01-13 16:37:28,245 [trainer.py] => shared_prompt_key: False
2024-01-13 16:37:28,245 [trainer.py] => batchwise_prompt: True
2024-01-13 16:37:28,245 [trainer.py] => embedding_key: cls
2024-01-13 16:37:28,245 [trainer.py] => predefined_key: 
2024-01-13 16:37:28,245 [trainer.py] => pull_constraint: True
2024-01-13 16:37:28,245 [trainer.py] => pull_constraint_coeff: 0.1
2024-01-13 16:37:28,245 [trainer.py] => semi_supervised_mode: True
2024-01-13 16:37:28,245 [trainer.py] => labeled_ratio: 0.05
2024-01-13 16:37:28,245 [trainer.py] => unlabeled_data_distribution_mode: previous_oot
2024-01-13 16:37:28,245 [trainer.py] => confidence_threshold: 0.9
2024-01-13 16:37:28,245 [trainer.py] => max_self_training_iteration: 3
Files already downloaded and verified
Files already downloaded and verified
2024-01-13 16:37:30,368 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-01-13 16:37:32,006 [vision_transformer_l2p.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2024-01-13 16:37:32,007 [vision_transformer_l2p.py] => Position embedding grid-size from [14, 14] to (14, 14)
2024-01-13 16:37:34,365 [l2p_self_training.py] => 85,940,836 model total parameters.
2024-01-13 16:37:34,366 [l2p_self_training.py] => 122,980 model training parameters.
2024-01-13 16:37:34,366 [l2p_self_training.py] => prompt.prompt: 38400
2024-01-13 16:37:34,366 [l2p_self_training.py] => prompt.prompt_key: 7680
2024-01-13 16:37:34,366 [l2p_self_training.py] => head.weight: 76800
2024-01-13 16:37:34,366 [l2p_self_training.py] => head.bias: 100
2024-01-13 16:37:34,367 [trainer.py] => All params: 171816392
2024-01-13 16:37:34,368 [trainer.py] => Trainable params: 122980
2024-01-13 16:37:34,368 [l2p_self_training.py] => Learning on 0-10
2024-01-13 16:37:34,998 [l2p_self_training.py] => train dataset length: 250
Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50: 100%|███████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.75s/it]
2024-01-13 16:37:53,729 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50
2024-01-13 16:37:53,732 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:38:08,207 [l2p_self_training.py] => 1038 unlabeled samples will be pseudo labeled
2024-01-13 16:38:08,208 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:38:08,208 [toolkit.py] => Pseudo Accuracy: 0.9788053949903661
2024-01-13 16:38:08,213 [l2p_self_training.py] => train dataset length: 1288
Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70: 100%|███████████████████████████████████████████████████| 5/5 [01:04<00:00, 12.92s/it]
2024-01-13 16:39:12,821 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70
2024-01-13 16:39:12,825 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:39:27,432 [l2p_self_training.py] => 1668 unlabeled samples will be pseudo labeled
2024-01-13 16:39:27,432 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:39:27,433 [toolkit.py] => Pseudo Accuracy: 0.9508393285371702
2024-01-13 16:39:27,438 [l2p_self_training.py] => train dataset length: 1918
Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70: 100%|███████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.71s/it]
2024-01-13 16:41:00,988 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70
2024-01-13 16:41:00,991 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:41:15,688 [l2p_self_training.py] => 1679 unlabeled samples will be pseudo labeled
2024-01-13 16:41:15,688 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:41:15,689 [toolkit.py] => Pseudo Accuracy: 0.9535437760571769
2024-01-13 16:41:21,731 [trainer.py] => No NME accuracy.
2024-01-13 16:41:21,731 [trainer.py] => CNN: {'total': 90.7, '00-09': 90.7, 'old': 0, 'new': 90.7}
2024-01-13 16:41:21,731 [trainer.py] => CNN top1 curve: [90.7]
2024-01-13 16:41:21,731 [trainer.py] => CNN top5 curve: [99.2]

Average Accuracy (CNN): 90.7
2024-01-13 16:41:21,731 [trainer.py] => Average Accuracy (CNN): 90.7 

2024-01-13 16:41:21,733 [trainer.py] => All params: 171816392
2024-01-13 16:41:21,734 [trainer.py] => Trainable params: 122980
2024-01-13 16:41:21,734 [l2p_self_training.py] => Learning on 10-20
2024-01-13 16:41:21,788 [l2p_self_training.py] => train dataset length: 250
Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95: 100%|██████████████████████████████████████████████████| 5/5 [00:24<00:00,  4.96s/it]
2024-01-13 16:41:46,570 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95
2024-01-13 16:41:46,572 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:42:02,705 [l2p_self_training.py] => 1541 unlabeled samples will be pseudo labeled
2024-01-13 16:42:02,706 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:42:02,707 [toolkit.py] => Pseudo Accuracy: 0.9565217391304348
2024-01-13 16:42:02,710 [l2p_self_training.py] => train dataset length: 1791
Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60: 100%|███████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.73s/it]
2024-01-13 16:43:36,344 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60
2024-01-13 16:43:36,348 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:43:52,565 [l2p_self_training.py] => 1794 unlabeled samples will be pseudo labeled
2024-01-13 16:43:52,565 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:43:52,566 [toolkit.py] => Pseudo Accuracy: 0.9308807134894092
2024-01-13 16:43:52,569 [l2p_self_training.py] => train dataset length: 2044
Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50: 100%|███████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.01s/it]
2024-01-13 16:45:37,614 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50
2024-01-13 16:45:37,617 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:45:53,817 [l2p_self_training.py] => 1922 unlabeled samples will be pseudo labeled
2024-01-13 16:45:53,818 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:45:53,818 [toolkit.py] => Pseudo Accuracy: 0.9167533818938606
2024-01-13 16:46:05,689 [trainer.py] => No NME accuracy.
2024-01-13 16:46:05,689 [trainer.py] => CNN: {'total': 48.5, '00-09': 1.9, '10-19': 95.1, 'old': 1.9, 'new': 95.1}
2024-01-13 16:46:05,689 [trainer.py] => CNN top1 curve: [90.7, 48.5]
2024-01-13 16:46:05,689 [trainer.py] => CNN top5 curve: [99.2, 54.8]

Average Accuracy (CNN): 69.6
2024-01-13 16:46:05,689 [trainer.py] => Average Accuracy (CNN): 69.6 

2024-01-13 16:46:05,690 [trainer.py] => All params: 171816392
2024-01-13 16:46:05,691 [trainer.py] => Trainable params: 122980
2024-01-13 16:46:05,691 [l2p_self_training.py] => Learning on 20-30
2024-01-13 16:46:05,727 [l2p_self_training.py] => train dataset length: 250
Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00: 100%|██████████████████████████████████████████████████| 5/5 [00:30<00:00,  6.14s/it]
2024-01-13 16:46:36,449 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00
2024-01-13 16:46:36,452 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:46:54,140 [l2p_self_training.py] => 1838 unlabeled samples will be pseudo labeled
2024-01-13 16:46:54,141 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:46:54,141 [toolkit.py] => Pseudo Accuracy: 0.9613710554951034
2024-01-13 16:46:54,146 [l2p_self_training.py] => train dataset length: 2088
Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43: 100%|██████████████████████████████████████████████████| 5/5 [01:53<00:00, 22.62s/it]
2024-01-13 16:48:47,243 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43
2024-01-13 16:48:47,245 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:49:04,874 [l2p_self_training.py] => 2263 unlabeled samples will be pseudo labeled
2024-01-13 16:49:04,874 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:49:04,875 [toolkit.py] => Pseudo Accuracy: 0.8811312417145383
2024-01-13 16:49:04,879 [l2p_self_training.py] => train dataset length: 2513
Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97: 100%|██████████████████████████████████████████████████| 5/5 [02:12<00:00, 26.42s/it]
2024-01-13 16:51:16,961 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97
2024-01-13 16:51:16,963 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:51:34,567 [l2p_self_training.py] => 2305 unlabeled samples will be pseudo labeled
2024-01-13 16:51:34,567 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:51:34,568 [toolkit.py] => Pseudo Accuracy: 0.879826464208243
2024-01-13 16:51:52,203 [trainer.py] => No NME accuracy.
2024-01-13 16:51:52,203 [trainer.py] => CNN: {'total': 31.97, '00-09': 0.0, '10-19': 0.5, '20-29': 95.4, 'old': 0.25, 'new': 95.4}
2024-01-13 16:51:52,203 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97]
2024-01-13 16:51:52,203 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0]

Average Accuracy (CNN): 57.056666666666665
2024-01-13 16:51:52,203 [trainer.py] => Average Accuracy (CNN): 57.056666666666665 

2024-01-13 16:51:52,205 [trainer.py] => All params: 171816392
2024-01-13 16:51:52,206 [trainer.py] => Trainable params: 122980
2024-01-13 16:51:52,206 [l2p_self_training.py] => Learning on 30-40
2024-01-13 16:51:52,248 [l2p_self_training.py] => train dataset length: 250
Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18: 100%|██████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.21s/it]
2024-01-13 16:52:28,294 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18
2024-01-13 16:52:28,297 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:52:47,402 [l2p_self_training.py] => 1712 unlabeled samples will be pseudo labeled
2024-01-13 16:52:47,402 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:52:47,403 [toolkit.py] => Pseudo Accuracy: 0.927570093457944
2024-01-13 16:52:47,408 [l2p_self_training.py] => train dataset length: 1962
Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70: 100%|██████████████████████████████████████████████████| 5/5 [01:52<00:00, 22.58s/it]
2024-01-13 16:54:40,285 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70
2024-01-13 16:54:40,288 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:54:59,314 [l2p_self_training.py] => 2365 unlabeled samples will be pseudo labeled
2024-01-13 16:54:59,314 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:54:59,315 [toolkit.py] => Pseudo Accuracy: 0.8228329809725159
2024-01-13 16:54:59,319 [l2p_self_training.py] => train dataset length: 2615
Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30: 100%|██████████████████████████████████████████████████| 5/5 [02:21<00:00, 28.37s/it]
2024-01-13 16:57:21,159 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30
2024-01-13 16:57:21,161 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:57:40,154 [l2p_self_training.py] => 2407 unlabeled samples will be pseudo labeled
2024-01-13 16:57:40,155 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:57:40,155 [toolkit.py] => Pseudo Accuracy: 0.7947652679684254
2024-01-13 16:58:03,483 [trainer.py] => No NME accuracy.
2024-01-13 16:58:03,483 [trainer.py] => CNN: {'total': 32.3, '00-09': 0.0, '10-19': 0.0, '20-29': 39.6, '30-39': 89.6, 'old': 13.2, 'new': 89.6}
2024-01-13 16:58:03,483 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3]
2024-01-13 16:58:03,484 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83]

Average Accuracy (CNN): 50.86749999999999
2024-01-13 16:58:03,484 [trainer.py] => Average Accuracy (CNN): 50.86749999999999 

2024-01-13 16:58:03,485 [trainer.py] => All params: 171816392
2024-01-13 16:58:03,487 [trainer.py] => Trainable params: 122980
2024-01-13 16:58:03,487 [l2p_self_training.py] => Learning on 40-50
2024-01-13 16:58:03,540 [l2p_self_training.py] => train dataset length: 250
Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.085, Train_accy 92.80, Test_accy 27.60: 100%|██████████████████████████████████████████████████| 5/5 [00:42<00:00,  8.43s/it]
2024-01-13 16:58:45,690 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.085, Train_accy 92.80, Test_accy 27.60
2024-01-13 16:58:45,693 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:59:06,164 [l2p_self_training.py] => 1937 unlabeled samples will be pseudo labeled
2024-01-13 16:59:06,164 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:59:06,164 [toolkit.py] => Pseudo Accuracy: 0.9210118740320082
2024-01-13 16:59:06,168 [l2p_self_training.py] => train dataset length: 2187
Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.146, Train_accy 94.60, Test_accy 31.74: 100%|██████████████████████████████████████████████████| 5/5 [02:08<00:00, 25.68s/it]
2024-01-13 17:01:14,593 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.146, Train_accy 94.60, Test_accy 31.74
2024-01-13 17:01:14,597 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:01:35,109 [l2p_self_training.py] => 2615 unlabeled samples will be pseudo labeled
2024-01-13 17:01:35,109 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:01:35,110 [toolkit.py] => Pseudo Accuracy: 0.8409177820267686
2024-01-13 17:01:35,115 [l2p_self_training.py] => train dataset length: 2865
Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.077, Train_accy 92.71, Test_accy 29.54: 100%|██████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.73s/it]
2024-01-13 17:04:13,761 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.077, Train_accy 92.71, Test_accy 29.54
2024-01-13 17:04:13,765 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:04:34,289 [l2p_self_training.py] => 2697 unlabeled samples will be pseudo labeled
2024-01-13 17:04:34,289 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:04:34,290 [toolkit.py] => Pseudo Accuracy: 0.8075639599555061
2024-01-13 17:05:03,362 [trainer.py] => No NME accuracy.
2024-01-13 17:05:03,362 [trainer.py] => CNN: {'total': 29.54, '00-09': 0.0, '10-19': 0.0, '20-29': 17.0, '30-39': 33.0, '40-49': 97.7, 'old': 12.5, 'new': 97.7}
2024-01-13 17:05:03,362 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54]
2024-01-13 17:05:03,362 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86]

Average Accuracy (CNN): 46.60199999999999
2024-01-13 17:05:03,363 [trainer.py] => Average Accuracy (CNN): 46.60199999999999 

2024-01-13 17:05:03,364 [trainer.py] => All params: 171816392
2024-01-13 17:05:03,365 [trainer.py] => Trainable params: 122980
2024-01-13 17:05:03,365 [l2p_self_training.py] => Learning on 50-60
2024-01-13 17:05:03,417 [l2p_self_training.py] => train dataset length: 250
Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.036, Train_accy 90.00, Test_accy 28.17: 100%|██████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.60s/it]
2024-01-13 17:05:51,416 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.036, Train_accy 90.00, Test_accy 28.17
2024-01-13 17:05:51,418 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:06:13,243 [l2p_self_training.py] => 1795 unlabeled samples will be pseudo labeled
2024-01-13 17:06:13,243 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:06:13,244 [toolkit.py] => Pseudo Accuracy: 0.9175487465181058
2024-01-13 17:06:13,249 [l2p_self_training.py] => train dataset length: 2045
Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.81, Test_accy 29.85: 100%|██████████████████████████████████████████████████| 5/5 [02:07<00:00, 25.53s/it]
2024-01-13 17:08:20,897 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.81, Test_accy 29.85
2024-01-13 17:08:20,900 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:08:42,750 [l2p_self_training.py] => 2532 unlabeled samples will be pseudo labeled
2024-01-13 17:08:42,751 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:08:42,752 [toolkit.py] => Pseudo Accuracy: 0.8135860979462876
2024-01-13 17:08:42,758 [l2p_self_training.py] => train dataset length: 2782
Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.066, Train_accy 92.42, Test_accy 29.10: 100%|██████████████████████████████████████████████████| 5/5 [02:40<00:00, 32.18s/it]
2024-01-13 17:11:23,641 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.066, Train_accy 92.42, Test_accy 29.10
2024-01-13 17:11:23,643 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:11:45,486 [l2p_self_training.py] => 2697 unlabeled samples will be pseudo labeled
2024-01-13 17:11:45,486 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:11:45,487 [toolkit.py] => Pseudo Accuracy: 0.7701149425287356
2024-01-13 17:12:20,253 [trainer.py] => No NME accuracy.
2024-01-13 17:12:20,253 [trainer.py] => CNN: {'total': 29.1, '00-09': 0.0, '10-19': 0.0, '20-29': 10.1, '30-39': 25.7, '40-49': 43.9, '50-59': 94.9, 'old': 15.94, 'new': 94.9}
2024-01-13 17:12:20,254 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1]
2024-01-13 17:12:20,254 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12]

Average Accuracy (CNN): 43.684999999999995
2024-01-13 17:12:20,254 [trainer.py] => Average Accuracy (CNN): 43.684999999999995 

2024-01-13 17:12:20,257 [trainer.py] => All params: 171816392
2024-01-13 17:12:20,260 [trainer.py] => Trainable params: 122980
2024-01-13 17:12:20,260 [l2p_self_training.py] => Learning on 60-70
2024-01-13 17:12:20,328 [l2p_self_training.py] => train dataset length: 250
Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.102, Train_accy 93.60, Test_accy 27.13: 100%|██████████████████████████████████████████████████| 5/5 [00:53<00:00, 10.65s/it]
2024-01-13 17:13:13,568 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.102, Train_accy 93.60, Test_accy 27.13
2024-01-13 17:13:13,571 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:13:36,864 [l2p_self_training.py] => 2074 unlabeled samples will be pseudo labeled
2024-01-13 17:13:36,864 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:13:36,865 [toolkit.py] => Pseudo Accuracy: 0.9387656702025072
2024-01-13 17:13:36,869 [l2p_self_training.py] => train dataset length: 2324
Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.93, Test_accy 30.16: 100%|██████████████████████████████████████████████████| 5/5 [02:26<00:00, 29.22s/it]
2024-01-13 17:16:02,954 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.93, Test_accy 30.16
2024-01-13 17:16:02,956 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:16:26,266 [l2p_self_training.py] => 2866 unlabeled samples will be pseudo labeled
2024-01-13 17:16:26,266 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:16:26,267 [toolkit.py] => Pseudo Accuracy: 0.8210048848569435
2024-01-13 17:16:26,274 [l2p_self_training.py] => train dataset length: 3116
Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.063, Train_accy 92.23, Test_accy 30.51: 100%|██████████████████████████████████████████████████| 5/5 [03:02<00:00, 36.43s/it]
2024-01-13 17:19:28,407 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.063, Train_accy 92.23, Test_accy 30.51
2024-01-13 17:19:28,409 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:19:51,817 [l2p_self_training.py] => 2931 unlabeled samples will be pseudo labeled
2024-01-13 17:19:51,817 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:19:51,818 [toolkit.py] => Pseudo Accuracy: 0.7922210849539406
2024-01-13 17:20:32,569 [trainer.py] => No NME accuracy.
2024-01-13 17:20:32,570 [trainer.py] => CNN: {'total': 30.51, '00-09': 0.0, '10-19': 0.0, '20-29': 16.4, '30-39': 22.9, '40-49': 31.0, '50-59': 45.1, '60-69': 98.2, 'old': 19.23, 'new': 98.2}
2024-01-13 17:20:32,570 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51]
2024-01-13 17:20:32,570 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73]

Average Accuracy (CNN): 41.802857142857135
2024-01-13 17:20:32,570 [trainer.py] => Average Accuracy (CNN): 41.802857142857135 

2024-01-13 17:20:32,572 [trainer.py] => All params: 171816392
2024-01-13 17:20:32,573 [trainer.py] => Trainable params: 122980
2024-01-13 17:20:32,573 [l2p_self_training.py] => Learning on 70-80
2024-01-13 17:20:32,635 [l2p_self_training.py] => train dataset length: 250
Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.019, Train_accy 90.80, Test_accy 24.54: 100%|██████████████████████████████████████████████████| 5/5 [00:59<00:00, 11.87s/it]
2024-01-13 17:21:32,003 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.019, Train_accy 90.80, Test_accy 24.54
2024-01-13 17:21:32,007 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:21:56,900 [l2p_self_training.py] => 1785 unlabeled samples will be pseudo labeled
2024-01-13 17:21:56,900 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:21:56,901 [toolkit.py] => Pseudo Accuracy: 0.8795518207282913
2024-01-13 17:21:56,905 [l2p_self_training.py] => train dataset length: 2035
Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.180, Train_accy 95.18, Test_accy 27.59: 100%|██████████████████████████████████████████████████| 5/5 [02:19<00:00, 27.94s/it]
2024-01-13 17:24:16,618 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.180, Train_accy 95.18, Test_accy 27.59
2024-01-13 17:24:16,620 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:24:41,605 [l2p_self_training.py] => 2886 unlabeled samples will be pseudo labeled
2024-01-13 17:24:41,605 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:24:41,606 [toolkit.py] => Pseudo Accuracy: 0.7366597366597366
2024-01-13 17:24:41,611 [l2p_self_training.py] => train dataset length: 3136
Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.039, Train_accy 91.04, Test_accy 27.49: 100%|██████████████████████████████████████████████████| 5/5 [03:10<00:00, 38.09s/it]
2024-01-13 17:27:52,075 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.039, Train_accy 91.04, Test_accy 27.49
2024-01-13 17:27:52,077 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:28:17,458 [l2p_self_training.py] => 3016 unlabeled samples will be pseudo labeled
2024-01-13 17:28:17,459 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:28:17,459 [toolkit.py] => Pseudo Accuracy: 0.7078912466843501
2024-01-13 17:29:04,373 [trainer.py] => No NME accuracy.
2024-01-13 17:29:04,373 [trainer.py] => CNN: {'total': 27.49, '00-09': 0.0, '10-19': 0.0, '20-29': 15.9, '30-39': 24.4, '40-49': 20.8, '50-59': 6.4, '60-69': 59.7, '70-79': 92.7, 'old': 18.17, 'new': 92.7}
2024-01-13 17:29:04,374 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49]
2024-01-13 17:29:04,374 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22]

Average Accuracy (CNN): 40.013749999999995
2024-01-13 17:29:04,374 [trainer.py] => Average Accuracy (CNN): 40.013749999999995 

2024-01-13 17:29:04,375 [trainer.py] => All params: 171816392
2024-01-13 17:29:04,376 [trainer.py] => Trainable params: 122980
2024-01-13 17:29:04,376 [l2p_self_training.py] => Learning on 80-90
2024-01-13 17:29:04,532 [l2p_self_training.py] => train dataset length: 250
Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.042, Train_accy 90.40, Test_accy 22.86: 100%|██████████████████████████████████████████████████| 5/5 [01:05<00:00, 13.16s/it]
2024-01-13 17:30:10,323 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.042, Train_accy 90.40, Test_accy 22.86
2024-01-13 17:30:10,325 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:30:36,707 [l2p_self_training.py] => 1985 unlabeled samples will be pseudo labeled
2024-01-13 17:30:36,707 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:30:36,708 [toolkit.py] => Pseudo Accuracy: 0.8937027707808565
2024-01-13 17:30:36,715 [l2p_self_training.py] => train dataset length: 2235
Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.116, Train_accy 94.18, Test_accy 24.93: 100%|██████████████████████████████████████████████████| 5/5 [02:34<00:00, 30.81s/it]
2024-01-13 17:33:10,742 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.116, Train_accy 94.18, Test_accy 24.93
2024-01-13 17:33:10,744 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:33:37,001 [l2p_self_training.py] => 2888 unlabeled samples will be pseudo labeled
2024-01-13 17:33:37,001 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:33:37,002 [toolkit.py] => Pseudo Accuracy: 0.7725069252077562
2024-01-13 17:33:37,008 [l2p_self_training.py] => train dataset length: 3138
Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.27, Test_accy 23.64: 100%|██████████████████████████████████████████████████| 5/5 [03:14<00:00, 38.85s/it]
2024-01-13 17:36:51,264 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.27, Test_accy 23.64
2024-01-13 17:36:51,268 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:37:17,441 [l2p_self_training.py] => 3082 unlabeled samples will be pseudo labeled
2024-01-13 17:37:17,442 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:37:17,443 [toolkit.py] => Pseudo Accuracy: 0.7196625567813109
2024-01-13 17:38:09,611 [trainer.py] => No NME accuracy.
2024-01-13 17:38:09,612 [trainer.py] => CNN: {'total': 23.64, '00-09': 0.0, '10-19': 0.0, '20-29': 10.3, '30-39': 20.5, '40-49': 11.8, '50-59': 2.0, '60-69': 36.6, '70-79': 35.3, '80-89': 96.3, 'old': 14.56, 'new': 96.3}
2024-01-13 17:38:09,612 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49, 23.64]
2024-01-13 17:38:09,612 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22, 30.0]

Average Accuracy (CNN): 38.194444444444436
2024-01-13 17:38:09,612 [trainer.py] => Average Accuracy (CNN): 38.194444444444436 

2024-01-13 17:38:09,614 [trainer.py] => All params: 171816392
2024-01-13 17:38:09,615 [trainer.py] => Trainable params: 122980
2024-01-13 17:38:09,615 [l2p_self_training.py] => Learning on 90-100
2024-01-13 17:38:09,766 [l2p_self_training.py] => train dataset length: 250
Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.020, Train_accy 90.00, Test_accy 23.96: 100%|██████████████████████████████████████████████████| 5/5 [01:10<00:00, 14.09s/it]
2024-01-13 17:39:20,225 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.020, Train_accy 90.00, Test_accy 23.96
2024-01-13 17:39:20,229 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:39:47,896 [l2p_self_training.py] => 1943 unlabeled samples will be pseudo labeled
2024-01-13 17:39:47,896 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:39:47,897 [toolkit.py] => Pseudo Accuracy: 0.9186824498198661
2024-01-13 17:39:47,906 [l2p_self_training.py] => train dataset length: 2193
Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.16, Test_accy 25.88: 100%|██████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.75s/it]
2024-01-13 17:42:26,652 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.16, Test_accy 25.88
2024-01-13 17:42:26,655 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:42:54,299 [l2p_self_training.py] => 2832 unlabeled samples will be pseudo labeled
2024-01-13 17:42:54,299 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:42:54,300 [toolkit.py] => Pseudo Accuracy: 0.7874293785310734
2024-01-13 17:42:54,305 [l2p_self_training.py] => train dataset length: 3082
Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.30, Test_accy 25.50: 100%|██████████████████████████████████████████████████| 5/5 [03:17<00:00, 39.48s/it]
2024-01-13 17:46:11,731 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.30, Test_accy 25.50
2024-01-13 17:46:11,733 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:46:39,313 [l2p_self_training.py] => 3086 unlabeled samples will be pseudo labeled
2024-01-13 17:46:39,314 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:46:39,315 [toolkit.py] => Pseudo Accuracy: 0.7300712896953986
2024-01-13 17:47:37,385 [trainer.py] => No NME accuracy.
2024-01-13 17:47:37,385 [trainer.py] => CNN: {'total': 25.5, '00-09': 0.0, '10-19': 0.0, '20-29': 13.6, '30-39': 23.2, '40-49': 12.6, '50-59': 1.9, '60-69': 25.5, '70-79': 9.5, '80-89': 73.7, '90-99': 95.0, 'old': 17.78, 'new': 95.0}
2024-01-13 17:47:37,385 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49, 23.64, 25.5]
2024-01-13 17:47:37,385 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22, 30.0, 30.6]

Average Accuracy (CNN): 36.925
2024-01-13 17:47:37,385 [trainer.py] => Average Accuracy (CNN): 36.925 