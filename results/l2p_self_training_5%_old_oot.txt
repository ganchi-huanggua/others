(lhz-torch-2.0) lhz@csgpu-SYS-4029GP-TRT:~/code/LAMDA-PILOT$ python main.py --config=exps/l2p_self_training.json
2024-01-13 16:37:28,244 [trainer.py] => config: exps/l2p_self_training.json
2024-01-13 16:37:28,244 [trainer.py] => prefix:  
2024-01-13 16:37:28,244 [trainer.py] => dataset: cifar224
2024-01-13 16:37:28,244 [trainer.py] => memory_size: 0
2024-01-13 16:37:28,244 [trainer.py] => memory_per_class: 0
2024-01-13 16:37:28,244 [trainer.py] => fixed_memory: False
2024-01-13 16:37:28,244 [trainer.py] => shuffle: True
2024-01-13 16:37:28,244 [trainer.py] => init_cls: 10
2024-01-13 16:37:28,244 [trainer.py] => increment: 10
2024-01-13 16:37:28,244 [trainer.py] => model_name: l2p_self_training
2024-01-13 16:37:28,244 [trainer.py] => backbone_type: vit_base_patch16_224_l2p
2024-01-13 16:37:28,244 [trainer.py] => get_original_backbone: True
2024-01-13 16:37:28,244 [trainer.py] => device: [device(type='cuda', index=5)]
2024-01-13 16:37:28,244 [trainer.py] => seed: 1993
2024-01-13 16:37:28,244 [trainer.py] => tuned_epoch: 5
2024-01-13 16:37:28,244 [trainer.py] => init_lr: 0.001875
2024-01-13 16:37:28,244 [trainer.py] => batch_size: 16
2024-01-13 16:37:28,244 [trainer.py] => weight_decay: 0
2024-01-13 16:37:28,244 [trainer.py] => min_lr: 1e-05
2024-01-13 16:37:28,244 [trainer.py] => optimizer: adam
2024-01-13 16:37:28,245 [trainer.py] => scheduler: constant
2024-01-13 16:37:28,245 [trainer.py] => reinit_optimizer: True
2024-01-13 16:37:28,245 [trainer.py] => global_pool: token
2024-01-13 16:37:28,245 [trainer.py] => head_type: prompt
2024-01-13 16:37:28,245 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2024-01-13 16:37:28,245 [trainer.py] => pretrained: True
2024-01-13 16:37:28,245 [trainer.py] => drop: 0.0
2024-01-13 16:37:28,245 [trainer.py] => drop_path: 0.0
2024-01-13 16:37:28,245 [trainer.py] => prompt_pool: True
2024-01-13 16:37:28,245 [trainer.py] => pool_size: 10
2024-01-13 16:37:28,245 [trainer.py] => length: 5
2024-01-13 16:37:28,245 [trainer.py] => top_k: 5
2024-01-13 16:37:28,245 [trainer.py] => initializer: uniform
2024-01-13 16:37:28,245 [trainer.py] => prompt_key: True
2024-01-13 16:37:28,245 [trainer.py] => prompt_key_init: uniform
2024-01-13 16:37:28,245 [trainer.py] => use_prompt_mask: False
2024-01-13 16:37:28,245 [trainer.py] => shared_prompt_pool: False
2024-01-13 16:37:28,245 [trainer.py] => shared_prompt_key: False
2024-01-13 16:37:28,245 [trainer.py] => batchwise_prompt: True
2024-01-13 16:37:28,245 [trainer.py] => embedding_key: cls
2024-01-13 16:37:28,245 [trainer.py] => predefined_key: 
2024-01-13 16:37:28,245 [trainer.py] => pull_constraint: True
2024-01-13 16:37:28,245 [trainer.py] => pull_constraint_coeff: 0.1
2024-01-13 16:37:28,245 [trainer.py] => semi_supervised_mode: True
2024-01-13 16:37:28,245 [trainer.py] => labeled_ratio: 0.05
2024-01-13 16:37:28,245 [trainer.py] => unlabeled_data_distribution_mode: previous_oot
2024-01-13 16:37:28,245 [trainer.py] => confidence_threshold: 0.9
2024-01-13 16:37:28,245 [trainer.py] => max_self_training_iteration: 3
Files already downloaded and verified
Files already downloaded and verified
2024-01-13 16:37:30,368 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-01-13 16:37:32,006 [vision_transformer_l2p.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2024-01-13 16:37:32,007 [vision_transformer_l2p.py] => Position embedding grid-size from [14, 14] to (14, 14)
2024-01-13 16:37:34,365 [l2p_self_training.py] => 85,940,836 model total parameters.
2024-01-13 16:37:34,366 [l2p_self_training.py] => 122,980 model training parameters.
2024-01-13 16:37:34,366 [l2p_self_training.py] => prompt.prompt: 38400
2024-01-13 16:37:34,366 [l2p_self_training.py] => prompt.prompt_key: 7680
2024-01-13 16:37:34,366 [l2p_self_training.py] => head.weight: 76800
2024-01-13 16:37:34,366 [l2p_self_training.py] => head.bias: 100
2024-01-13 16:37:34,367 [trainer.py] => All params: 171816392
2024-01-13 16:37:34,368 [trainer.py] => Trainable params: 122980
2024-01-13 16:37:34,368 [l2p_self_training.py] => Learning on 0-10
2024-01-13 16:37:34,998 [l2p_self_training.py] => train dataset length: 250
Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50: 100%|███████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.75s/it]
2024-01-13 16:37:53,729 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50
2024-01-13 16:37:53,732 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:38:08,207 [l2p_self_training.py] => 1038 unlabeled samples will be pseudo labeled
2024-01-13 16:38:08,208 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:38:08,208 [toolkit.py] => Pseudo Accuracy: 0.9788053949903661
2024-01-13 16:38:08,213 [l2p_self_training.py] => train dataset length: 1288
Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70: 100%|███████████████████████████████████████████████████| 5/5 [01:04<00:00, 12.92s/it]
2024-01-13 16:39:12,821 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70
2024-01-13 16:39:12,825 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:39:27,432 [l2p_self_training.py] => 1668 unlabeled samples will be pseudo labeled
2024-01-13 16:39:27,432 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:39:27,433 [toolkit.py] => Pseudo Accuracy: 0.9508393285371702
2024-01-13 16:39:27,438 [l2p_self_training.py] => train dataset length: 1918
Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70: 100%|███████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.71s/it]
2024-01-13 16:41:00,988 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70
2024-01-13 16:41:00,991 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:41:15,688 [l2p_self_training.py] => 1679 unlabeled samples will be pseudo labeled
2024-01-13 16:41:15,688 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:41:15,689 [toolkit.py] => Pseudo Accuracy: 0.9535437760571769
2024-01-13 16:41:21,731 [trainer.py] => No NME accuracy.
2024-01-13 16:41:21,731 [trainer.py] => CNN: {'total': 90.7, '00-09': 90.7, 'old': 0, 'new': 90.7}
2024-01-13 16:41:21,731 [trainer.py] => CNN top1 curve: [90.7]
2024-01-13 16:41:21,731 [trainer.py] => CNN top5 curve: [99.2]

Average Accuracy (CNN): 90.7
2024-01-13 16:41:21,731 [trainer.py] => Average Accuracy (CNN): 90.7 

2024-01-13 16:41:21,733 [trainer.py] => All params: 171816392
2024-01-13 16:41:21,734 [trainer.py] => Trainable params: 122980
2024-01-13 16:41:21,734 [l2p_self_training.py] => Learning on 10-20
2024-01-13 16:41:21,788 [l2p_self_training.py] => train dataset length: 250
Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95: 100%|██████████████████████████████████████████████████| 5/5 [00:24<00:00,  4.96s/it]
2024-01-13 16:41:46,570 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95
2024-01-13 16:41:46,572 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:42:02,705 [l2p_self_training.py] => 1541 unlabeled samples will be pseudo labeled
2024-01-13 16:42:02,706 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:42:02,707 [toolkit.py] => Pseudo Accuracy: 0.9565217391304348
2024-01-13 16:42:02,710 [l2p_self_training.py] => train dataset length: 1791
Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60: 100%|███████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.73s/it]
2024-01-13 16:43:36,344 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60
2024-01-13 16:43:36,348 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:43:52,565 [l2p_self_training.py] => 1794 unlabeled samples will be pseudo labeled
2024-01-13 16:43:52,565 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:43:52,566 [toolkit.py] => Pseudo Accuracy: 0.9308807134894092
2024-01-13 16:43:52,569 [l2p_self_training.py] => train dataset length: 2044
Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50: 100%|███████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.01s/it]
2024-01-13 16:45:37,614 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50
2024-01-13 16:45:37,617 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:45:53,817 [l2p_self_training.py] => 1922 unlabeled samples will be pseudo labeled
2024-01-13 16:45:53,818 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:45:53,818 [toolkit.py] => Pseudo Accuracy: 0.9167533818938606
2024-01-13 16:46:05,689 [trainer.py] => No NME accuracy.
2024-01-13 16:46:05,689 [trainer.py] => CNN: {'total': 48.5, '00-09': 1.9, '10-19': 95.1, 'old': 1.9, 'new': 95.1}
2024-01-13 16:46:05,689 [trainer.py] => CNN top1 curve: [90.7, 48.5]
2024-01-13 16:46:05,689 [trainer.py] => CNN top5 curve: [99.2, 54.8]

Average Accuracy (CNN): 69.6
2024-01-13 16:46:05,689 [trainer.py] => Average Accuracy (CNN): 69.6 

2024-01-13 16:46:05,690 [trainer.py] => All params: 171816392
2024-01-13 16:46:05,691 [trainer.py] => Trainable params: 122980
2024-01-13 16:46:05,691 [l2p_self_training.py] => Learning on 20-30
2024-01-13 16:46:05,727 [l2p_self_training.py] => train dataset length: 250
Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00: 100%|██████████████████████████████████████████████████| 5/5 [00:30<00:00,  6.14s/it]
2024-01-13 16:46:36,449 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00
2024-01-13 16:46:36,452 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:46:54,140 [l2p_self_training.py] => 1838 unlabeled samples will be pseudo labeled
2024-01-13 16:46:54,141 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:46:54,141 [toolkit.py] => Pseudo Accuracy: 0.9613710554951034
2024-01-13 16:46:54,146 [l2p_self_training.py] => train dataset length: 2088
Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43: 100%|██████████████████████████████████████████████████| 5/5 [01:53<00:00, 22.62s/it]
2024-01-13 16:48:47,243 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43
2024-01-13 16:48:47,245 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:49:04,874 [l2p_self_training.py] => 2263 unlabeled samples will be pseudo labeled
2024-01-13 16:49:04,874 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:49:04,875 [toolkit.py] => Pseudo Accuracy: 0.8811312417145383
2024-01-13 16:49:04,879 [l2p_self_training.py] => train dataset length: 2513
Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97: 100%|██████████████████████████████████████████████████| 5/5 [02:12<00:00, 26.42s/it]
2024-01-13 16:51:16,961 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97
2024-01-13 16:51:16,963 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:51:34,567 [l2p_self_training.py] => 2305 unlabeled samples will be pseudo labeled
2024-01-13 16:51:34,567 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:51:34,568 [toolkit.py] => Pseudo Accuracy: 0.879826464208243
2024-01-13 16:51:52,203 [trainer.py] => No NME accuracy.
2024-01-13 16:51:52,203 [trainer.py] => CNN: {'total': 31.97, '00-09': 0.0, '10-19': 0.5, '20-29': 95.4, 'old': 0.25, 'new': 95.4}
2024-01-13 16:51:52,203 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97]
2024-01-13 16:51:52,203 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0]

Average Accuracy (CNN): 57.056666666666665
2024-01-13 16:51:52,203 [trainer.py] => Average Accuracy (CNN): 57.056666666666665 

2024-01-13 16:51:52,205 [trainer.py] => All params: 171816392
2024-01-13 16:51:52,206 [trainer.py] => Trainable params: 122980
2024-01-13 16:51:52,206 [l2p_self_training.py] => Learning on 30-40
2024-01-13 16:51:52,248 [l2p_self_training.py] => train dataset length: 250
Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18: 100%|██████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.21s/it]
2024-01-13 16:52:28,294 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18
2024-01-13 16:52:28,297 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:52:47,402 [l2p_self_training.py] => 1712 unlabeled samples will be pseudo labeled
2024-01-13 16:52:47,402 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:52:47,403 [toolkit.py] => Pseudo Accuracy: 0.927570093457944
2024-01-13 16:52:47,408 [l2p_self_training.py] => train dataset length: 1962
Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70: 100%|██████████████████████████████████████████████████| 5/5 [01:52<00:00, 22.58s/it]
2024-01-13 16:54:40,285 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70
2024-01-13 16:54:40,288 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:54:59,314 [l2p_self_training.py] => 2365 unlabeled samples will be pseudo labeled
2024-01-13 16:54:59,314 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:54:59,315 [toolkit.py] => Pseudo Accuracy: 0.8228329809725159
2024-01-13 16:54:59,319 [l2p_self_training.py] => train dataset length: 2615
Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30: 100%|██████████████████████████████████████████████████| 5/5 [02:21<00:00, 28.37s/it]
2024-01-13 16:57:21,159 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30
2024-01-13 16:57:21,161 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:57:40,154 [l2p_self_training.py] => 2407 unlabeled samples will be pseudo labeled
2024-01-13 16:57:40,155 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:57:40,155 [toolkit.py] => Pseudo Accuracy: 0.7947652679684254
2024-01-13 16:58:03,483 [trainer.py] => No NME accuracy.
2024-01-13 16:58:03,483 [trainer.py] => CNN: {'total': 32.3, '00-09': 0.0, '10-19': 0.0, '20-29': 39.6, '30-39': 89.6, 'old': 13.2, 'new': 89.6}
2024-01-13 16:58:03,483 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3]
2024-01-13 16:58:03,484 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83]

Average Accuracy (CNN): 50.86749999999999
2024-01-13 16:58:03,484 [trainer.py] => Average Accuracy (CNN): 50.86749999999999 

2024-01-13 16:58:03,485 [trainer.py] => All params: 171816392
2024-01-13 16:58:03,487 [trainer.py] => Trainable params: 122980
2024-01-13 16:58:03,487 [l2p_self_training.py] => Learning on 40-50
2024-01-13 16:58:03,540 [l2p_self_training.py] => train dataset length: 250
Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.085, Train_accy 92.80, Test_accy 27.60: 100%|██████████████████████████████████████████████████| 5/5 [00:42<00:00,  8.43s/it]
2024-01-13 16:58:45,690 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.085, Train_accy 92.80, Test_accy 27.60
2024-01-13 16:58:45,693 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:59:06,164 [l2p_self_training.py] => 1937 unlabeled samples will be pseudo labeled
2024-01-13 16:59:06,164 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:59:06,164 [toolkit.py] => Pseudo Accuracy: 0.9210118740320082
2024-01-13 16:59:06,168 [l2p_self_training.py] => train dataset length: 2187
Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.146, Train_accy 94.60, Test_accy 31.74: 100%|██████████████████████████████████████████████████| 5/5 [02:08<00:00, 25.68s/it]
2024-01-13 17:01:14,593 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.146, Train_accy 94.60, Test_accy 31.74
2024-01-13 17:01:14,597 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:01:35,109 [l2p_self_training.py] => 2615 unlabeled samples will be pseudo labeled
2024-01-13 17:01:35,109 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:01:35,110 [toolkit.py] => Pseudo Accuracy: 0.8409177820267686
2024-01-13 17:01:35,115 [l2p_self_training.py] => train dataset length: 2865
Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.077, Train_accy 92.71, Test_accy 29.54: 100%|██████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.73s/it]
2024-01-13 17:04:13,761 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.077, Train_accy 92.71, Test_accy 29.54
2024-01-13 17:04:13,765 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:04:34,289 [l2p_self_training.py] => 2697 unlabeled samples will be pseudo labeled
2024-01-13 17:04:34,289 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:04:34,290 [toolkit.py] => Pseudo Accuracy: 0.8075639599555061
2024-01-13 17:05:03,362 [trainer.py] => No NME accuracy.
2024-01-13 17:05:03,362 [trainer.py] => CNN: {'total': 29.54, '00-09': 0.0, '10-19': 0.0, '20-29': 17.0, '30-39': 33.0, '40-49': 97.7, 'old': 12.5, 'new': 97.7}
2024-01-13 17:05:03,362 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54]
2024-01-13 17:05:03,362 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86]

Average Accuracy (CNN): 46.60199999999999
2024-01-13 17:05:03,363 [trainer.py] => Average Accuracy (CNN): 46.60199999999999 

2024-01-13 17:05:03,364 [trainer.py] => All params: 171816392
2024-01-13 17:05:03,365 [trainer.py] => Trainable params: 122980
2024-01-13 17:05:03,365 [l2p_self_training.py] => Learning on 50-60
2024-01-13 17:05:03,417 [l2p_self_training.py] => train dataset length: 250
Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.036, Train_accy 90.00, Test_accy 28.17: 100%|██████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.60s/it]
2024-01-13 17:05:51,416 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.036, Train_accy 90.00, Test_accy 28.17
2024-01-13 17:05:51,418 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:06:13,243 [l2p_self_training.py] => 1795 unlabeled samples will be pseudo labeled
2024-01-13 17:06:13,243 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:06:13,244 [toolkit.py] => Pseudo Accuracy: 0.9175487465181058
2024-01-13 17:06:13,249 [l2p_self_training.py] => train dataset length: 2045
Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.81, Test_accy 29.85: 100%|██████████████████████████████████████████████████| 5/5 [02:07<00:00, 25.53s/it]
2024-01-13 17:08:20,897 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.81, Test_accy 29.85
2024-01-13 17:08:20,900 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:08:42,750 [l2p_self_training.py] => 2532 unlabeled samples will be pseudo labeled
2024-01-13 17:08:42,751 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:08:42,752 [toolkit.py] => Pseudo Accuracy: 0.8135860979462876
2024-01-13 17:08:42,758 [l2p_self_training.py] => train dataset length: 2782
Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.066, Train_accy 92.42, Test_accy 29.10: 100%|██████████████████████████████████████████████████| 5/5 [02:40<00:00, 32.18s/it]
2024-01-13 17:11:23,641 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.066, Train_accy 92.42, Test_accy 29.10
2024-01-13 17:11:23,643 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:11:45,486 [l2p_self_training.py] => 2697 unlabeled samples will be pseudo labeled
2024-01-13 17:11:45,486 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:11:45,487 [toolkit.py] => Pseudo Accuracy: 0.7701149425287356
2024-01-13 17:12:20,253 [trainer.py] => No NME accuracy.
2024-01-13 17:12:20,253 [trainer.py] => CNN: {'total': 29.1, '00-09': 0.0, '10-19': 0.0, '20-29': 10.1, '30-39': 25.7, '40-49': 43.9, '50-59': 94.9, 'old': 15.94, 'new': 94.9}
2024-01-13 17:12:20,254 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1]
2024-01-13 17:12:20,254 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12]

Average Accuracy (CNN): 43.684999999999995
2024-01-13 17:12:20,254 [trainer.py] => Average Accuracy (CNN): 43.684999999999995 

2024-01-13 17:12:20,257 [trainer.py] => All params: 171816392
2024-01-13 17:12:20,260 [trainer.py] => Trainable params: 122980
2024-01-13 17:12:20,260 [l2p_self_training.py] => Learning on 60-70
2024-01-13 17:12:20,328 [l2p_self_training.py] => train dataset length: 250
Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.102, Train_accy 93.60, Test_accy 27.13: 100%|██████████████████████████████████████████████████| 5/5 [00:53<00:00, 10.65s/it]
2024-01-13 17:13:13,568 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.102, Train_accy 93.60, Test_accy 27.13
2024-01-13 17:13:13,571 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:13:36,864 [l2p_self_training.py] => 2074 unlabeled samples will be pseudo labeled
2024-01-13 17:13:36,864 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:13:36,865 [toolkit.py] => Pseudo Accuracy: 0.9387656702025072
2024-01-13 17:13:36,869 [l2p_self_training.py] => train dataset length: 2324
Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.93, Test_accy 30.16: 100%|██████████████████████████████████████████████████| 5/5 [02:26<00:00, 29.22s/it]
2024-01-13 17:16:02,954 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.93, Test_accy 30.16
2024-01-13 17:16:02,956 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:16:26,266 [l2p_self_training.py] => 2866 unlabeled samples will be pseudo labeled
2024-01-13 17:16:26,266 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:16:26,267 [toolkit.py] => Pseudo Accuracy: 0.8210048848569435
2024-01-13 17:16:26,274 [l2p_self_training.py] => train dataset length: 3116
Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.063, Train_accy 92.23, Test_accy 30.51: 100%|██████████████████████████████████████████████████| 5/5 [03:02<00:00, 36.43s/it]
2024-01-13 17:19:28,407 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.063, Train_accy 92.23, Test_accy 30.51
2024-01-13 17:19:28,409 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:19:51,817 [l2p_self_training.py] => 2931 unlabeled samples will be pseudo labeled
2024-01-13 17:19:51,817 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:19:51,818 [toolkit.py] => Pseudo Accuracy: 0.7922210849539406
2024-01-13 17:20:32,569 [trainer.py] => No NME accuracy.
2024-01-13 17:20:32,570 [trainer.py] => CNN: {'total': 30.51, '00-09': 0.0, '10-19': 0.0, '20-29': 16.4, '30-39': 22.9, '40-49': 31.0, '50-59': 45.1, '60-69': 98.2, 'old': 19.23, 'new': 98.2}
2024-01-13 17:20:32,570 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51]
2024-01-13 17:20:32,570 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73]

Average Accuracy (CNN): 41.802857142857135
2024-01-13 17:20:32,570 [trainer.py] => Average Accuracy (CNN): 41.802857142857135 

2024-01-13 17:20:32,572 [trainer.py] => All params: 171816392
2024-01-13 17:20:32,573 [trainer.py] => Trainable params: 122980
2024-01-13 17:20:32,573 [l2p_self_training.py] => Learning on 70-80
2024-01-13 17:20:32,635 [l2p_self_training.py] => train dataset length: 250
Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.019, Train_accy 90.80, Test_accy 24.54: 100%|██████████████████████████████████████████████████| 5/5 [00:59<00:00, 11.87s/it]
2024-01-13 17:21:32,003 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.019, Train_accy 90.80, Test_accy 24.54
2024-01-13 17:21:32,007 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:21:56,900 [l2p_self_training.py] => 1785 unlabeled samples will be pseudo labeled
2024-01-13 17:21:56,900 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:21:56,901 [toolkit.py] => Pseudo Accuracy: 0.8795518207282913
2024-01-13 17:21:56,905 [l2p_self_training.py] => train dataset length: 2035
Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.180, Train_accy 95.18, Test_accy 27.59: 100%|██████████████████████████████████████████████████| 5/5 [02:19<00:00, 27.94s/it]
2024-01-13 17:24:16,618 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.180, Train_accy 95.18, Test_accy 27.59
2024-01-13 17:24:16,620 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:24:41,605 [l2p_self_training.py] => 2886 unlabeled samples will be pseudo labeled
2024-01-13 17:24:41,605 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:24:41,606 [toolkit.py] => Pseudo Accuracy: 0.7366597366597366
2024-01-13 17:24:41,611 [l2p_self_training.py] => train dataset length: 3136
Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.039, Train_accy 91.04, Test_accy 27.49: 100%|██████████████████████████████████████████████████| 5/5 [03:10<00:00, 38.09s/it]
2024-01-13 17:27:52,075 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.039, Train_accy 91.04, Test_accy 27.49
2024-01-13 17:27:52,077 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:28:17,458 [l2p_self_training.py] => 3016 unlabeled samples will be pseudo labeled
2024-01-13 17:28:17,459 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:28:17,459 [toolkit.py] => Pseudo Accuracy: 0.7078912466843501
2024-01-13 17:29:04,373 [trainer.py] => No NME accuracy.
2024-01-13 17:29:04,373 [trainer.py] => CNN: {'total': 27.49, '00-09': 0.0, '10-19': 0.0, '20-29': 15.9, '30-39': 24.4, '40-49': 20.8, '50-59': 6.4, '60-69': 59.7, '70-79': 92.7, 'old': 18.17, 'new': 92.7}
2024-01-13 17:29:04,374 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49]
2024-01-13 17:29:04,374 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22]

Average Accuracy (CNN): 40.013749999999995
2024-01-13 17:29:04,374 [trainer.py] => Average Accuracy (CNN): 40.013749999999995 

2024-01-13 17:29:04,375 [trainer.py] => All params: 171816392
2024-01-13 17:29:04,376 [trainer.py] => Trainable params: 122980
2024-01-13 17:29:04,376 [l2p_self_training.py] => Learning on 80-90
2024-01-13 17:29:04,532 [l2p_self_training.py] => train dataset length: 250
Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.042, Train_accy 90.40, Test_accy 22.86: 100%|██████████████████████████████████████████████████| 5/5 [01:05<00:00, 13.16s/it]
2024-01-13 17:30:10,323 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.042, Train_accy 90.40, Test_accy 22.86
2024-01-13 17:30:10,325 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:30:36,707 [l2p_self_training.py] => 1985 unlabeled samples will be pseudo labeled
2024-01-13 17:30:36,707 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:30:36,708 [toolkit.py] => Pseudo Accuracy: 0.8937027707808565
2024-01-13 17:30:36,715 [l2p_self_training.py] => train dataset length: 2235
Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.116, Train_accy 94.18, Test_accy 24.93: 100%|██████████████████████████████████████████████████| 5/5 [02:34<00:00, 30.81s/it]
2024-01-13 17:33:10,742 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.116, Train_accy 94.18, Test_accy 24.93
2024-01-13 17:33:10,744 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:33:37,001 [l2p_self_training.py] => 2888 unlabeled samples will be pseudo labeled
2024-01-13 17:33:37,001 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:33:37,002 [toolkit.py] => Pseudo Accuracy: 0.7725069252077562
2024-01-13 17:33:37,008 [l2p_self_training.py] => train dataset length: 3138
Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.27, Test_accy 23.64: 100%|██████████████████████████████████████████████████| 5/5 [03:14<00:00, 38.85s/it]
2024-01-13 17:36:51,264 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.27, Test_accy 23.64
2024-01-13 17:36:51,268 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:37:17,441 [l2p_self_training.py] => 3082 unlabeled samples will be pseudo labeled
2024-01-13 17:37:17,442 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:37:17,443 [toolkit.py] => Pseudo Accuracy: 0.7196625567813109
2024-01-13 17:38:09,611 [trainer.py] => No NME accuracy.
2024-01-13 17:38:09,612 [trainer.py] => CNN: {'total': 23.64, '00-09': 0.0, '10-19': 0.0, '20-29': 10.3, '30-39': 20.5, '40-49': 11.8, '50-59': 2.0, '60-69': 36.6, '70-79': 35.3, '80-89': 96.3, 'old': 14.56, 'new': 96.3}
2024-01-13 17:38:09,612 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49, 23.64]
2024-01-13 17:38:09,612 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22, 30.0]

Average Accuracy (CNN): 38.194444444444436
2024-01-13 17:38:09,612 [trainer.py] => Average Accuracy (CNN): 38.194444444444436 

2024-01-13 17:38:09,614 [trainer.py] => All params: 171816392
2024-01-13 17:38:09,615 [trainer.py] => Trainable params: 122980
2024-01-13 17:38:09,615 [l2p_self_training.py] => Learning on 90-100
2024-01-13 17:38:09,766 [l2p_self_training.py] => train dataset length: 250
Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.020, Train_accy 90.00, Test_accy 23.96: 100%|██████████████████████████████████████████████████| 5/5 [01:10<00:00, 14.09s/it]
2024-01-13 17:39:20,225 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.020, Train_accy 90.00, Test_accy 23.96
2024-01-13 17:39:20,229 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:39:47,896 [l2p_self_training.py] => 1943 unlabeled samples will be pseudo labeled
2024-01-13 17:39:47,896 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:39:47,897 [toolkit.py] => Pseudo Accuracy: 0.9186824498198661
2024-01-13 17:39:47,906 [l2p_self_training.py] => train dataset length: 2193
Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.16, Test_accy 25.88: 100%|██████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.75s/it]
2024-01-13 17:42:26,652 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.16, Test_accy 25.88
2024-01-13 17:42:26,655 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:42:54,299 [l2p_self_training.py] => 2832 unlabeled samples will be pseudo labeled
2024-01-13 17:42:54,299 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:42:54,300 [toolkit.py] => Pseudo Accuracy: 0.7874293785310734
2024-01-13 17:42:54,305 [l2p_self_training.py] => train dataset length: 3082
Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.30, Test_accy 25.50: 100%|██████████████████████████████████████████████████| 5/5 [03:17<00:00, 39.48s/it]
2024-01-13 17:46:11,731 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.30, Test_accy 25.50
2024-01-13 17:46:11,733 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:46:39,313 [l2p_self_training.py] => 3086 unlabeled samples will be pseudo labeled
2024-01-13 17:46:39,314 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:46:39,315 [toolkit.py] => Pseudo Accuracy: 0.7300712896953986
2024-01-13 17:47:37,385 [trainer.py] => No NME accuracy.
2024-01-13 17:47:37,385 [trainer.py] => CNN: {'total': 25.5, '00-09': 0.0, '10-19': 0.0, '20-29': 13.6, '30-39': 23.2, '40-49': 12.6, '50-59': 1.9, '60-69': 25.5, '70-79': 9.5, '80-89': 73.7, '90-99': 95.0, 'old': 17.78, 'new': 95.0}
2024-01-13 17:47:37,385 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49, 23.64, 25.5]
2024-01-13 17:47:37,385 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22, 30.0, 30.6]

Average Accuracy (CNN): 36.925
2024-01-13 17:47:37,385 [trainer.py] => Average Accuracy (CNN): 36.925 (lhz-torch-2.0) lhz@csgpu-SYS-4029GP-TRT:~/code/LAMDA-PILOT$ python main.py --config=exps/l2p_self_training.json
2024-01-13 16:37:28,244 [trainer.py] => config: exps/l2p_self_training.json
2024-01-13 16:37:28,244 [trainer.py] => prefix:  
2024-01-13 16:37:28,244 [trainer.py] => dataset: cifar224
2024-01-13 16:37:28,244 [trainer.py] => memory_size: 0
2024-01-13 16:37:28,244 [trainer.py] => memory_per_class: 0
2024-01-13 16:37:28,244 [trainer.py] => fixed_memory: False
2024-01-13 16:37:28,244 [trainer.py] => shuffle: True
2024-01-13 16:37:28,244 [trainer.py] => init_cls: 10
2024-01-13 16:37:28,244 [trainer.py] => increment: 10
2024-01-13 16:37:28,244 [trainer.py] => model_name: l2p_self_training
2024-01-13 16:37:28,244 [trainer.py] => backbone_type: vit_base_patch16_224_l2p
2024-01-13 16:37:28,244 [trainer.py] => get_original_backbone: True
2024-01-13 16:37:28,244 [trainer.py] => device: [device(type='cuda', index=5)]
2024-01-13 16:37:28,244 [trainer.py] => seed: 1993
2024-01-13 16:37:28,244 [trainer.py] => tuned_epoch: 5
2024-01-13 16:37:28,244 [trainer.py] => init_lr: 0.001875
2024-01-13 16:37:28,244 [trainer.py] => batch_size: 16
2024-01-13 16:37:28,244 [trainer.py] => weight_decay: 0
2024-01-13 16:37:28,244 [trainer.py] => min_lr: 1e-05
2024-01-13 16:37:28,244 [trainer.py] => optimizer: adam
2024-01-13 16:37:28,245 [trainer.py] => scheduler: constant
2024-01-13 16:37:28,245 [trainer.py] => reinit_optimizer: True
2024-01-13 16:37:28,245 [trainer.py] => global_pool: token
2024-01-13 16:37:28,245 [trainer.py] => head_type: prompt
2024-01-13 16:37:28,245 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2024-01-13 16:37:28,245 [trainer.py] => pretrained: True
2024-01-13 16:37:28,245 [trainer.py] => drop: 0.0
2024-01-13 16:37:28,245 [trainer.py] => drop_path: 0.0
2024-01-13 16:37:28,245 [trainer.py] => prompt_pool: True
2024-01-13 16:37:28,245 [trainer.py] => pool_size: 10
2024-01-13 16:37:28,245 [trainer.py] => length: 5
2024-01-13 16:37:28,245 [trainer.py] => top_k: 5
2024-01-13 16:37:28,245 [trainer.py] => initializer: uniform
2024-01-13 16:37:28,245 [trainer.py] => prompt_key: True
2024-01-13 16:37:28,245 [trainer.py] => prompt_key_init: uniform
2024-01-13 16:37:28,245 [trainer.py] => use_prompt_mask: False
2024-01-13 16:37:28,245 [trainer.py] => shared_prompt_pool: False
2024-01-13 16:37:28,245 [trainer.py] => shared_prompt_key: False
2024-01-13 16:37:28,245 [trainer.py] => batchwise_prompt: True
2024-01-13 16:37:28,245 [trainer.py] => embedding_key: cls
2024-01-13 16:37:28,245 [trainer.py] => predefined_key: 
2024-01-13 16:37:28,245 [trainer.py] => pull_constraint: True
2024-01-13 16:37:28,245 [trainer.py] => pull_constraint_coeff: 0.1
2024-01-13 16:37:28,245 [trainer.py] => semi_supervised_mode: True
2024-01-13 16:37:28,245 [trainer.py] => labeled_ratio: 0.05
2024-01-13 16:37:28,245 [trainer.py] => unlabeled_data_distribution_mode: previous_oot
2024-01-13 16:37:28,245 [trainer.py] => confidence_threshold: 0.9
2024-01-13 16:37:28,245 [trainer.py] => max_self_training_iteration: 3
Files already downloaded and verified
Files already downloaded and verified
2024-01-13 16:37:30,368 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-01-13 16:37:32,006 [vision_transformer_l2p.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2024-01-13 16:37:32,007 [vision_transformer_l2p.py] => Position embedding grid-size from [14, 14] to (14, 14)
2024-01-13 16:37:34,365 [l2p_self_training.py] => 85,940,836 model total parameters.
2024-01-13 16:37:34,366 [l2p_self_training.py] => 122,980 model training parameters.
2024-01-13 16:37:34,366 [l2p_self_training.py] => prompt.prompt: 38400
2024-01-13 16:37:34,366 [l2p_self_training.py] => prompt.prompt_key: 7680
2024-01-13 16:37:34,366 [l2p_self_training.py] => head.weight: 76800
2024-01-13 16:37:34,366 [l2p_self_training.py] => head.bias: 100
2024-01-13 16:37:34,367 [trainer.py] => All params: 171816392
2024-01-13 16:37:34,368 [trainer.py] => Trainable params: 122980
2024-01-13 16:37:34,368 [l2p_self_training.py] => Learning on 0-10
2024-01-13 16:37:34,998 [l2p_self_training.py] => train dataset length: 250
Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50: 100%|███████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.75s/it]
2024-01-13 16:37:53,729 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50
2024-01-13 16:37:53,732 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:38:08,207 [l2p_self_training.py] => 1038 unlabeled samples will be pseudo labeled
2024-01-13 16:38:08,208 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:38:08,208 [toolkit.py] => Pseudo Accuracy: 0.9788053949903661
2024-01-13 16:38:08,213 [l2p_self_training.py] => train dataset length: 1288
Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70: 100%|███████████████████████████████████████████████████| 5/5 [01:04<00:00, 12.92s/it]
2024-01-13 16:39:12,821 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70
2024-01-13 16:39:12,825 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:39:27,432 [l2p_self_training.py] => 1668 unlabeled samples will be pseudo labeled
2024-01-13 16:39:27,432 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:39:27,433 [toolkit.py] => Pseudo Accuracy: 0.9508393285371702
2024-01-13 16:39:27,438 [l2p_self_training.py] => train dataset length: 1918
Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70: 100%|███████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.71s/it]
2024-01-13 16:41:00,988 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70
2024-01-13 16:41:00,991 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:41:15,688 [l2p_self_training.py] => 1679 unlabeled samples will be pseudo labeled
2024-01-13 16:41:15,688 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:41:15,689 [toolkit.py] => Pseudo Accuracy: 0.9535437760571769
2024-01-13 16:41:21,731 [trainer.py] => No NME accuracy.
2024-01-13 16:41:21,731 [trainer.py] => CNN: {'total': 90.7, '00-09': 90.7, 'old': 0, 'new': 90.7}
2024-01-13 16:41:21,731 [trainer.py] => CNN top1 curve: [90.7]
2024-01-13 16:41:21,731 [trainer.py] => CNN top5 curve: [99.2]

Average Accuracy (CNN): 90.7
2024-01-13 16:41:21,731 [trainer.py] => Average Accuracy (CNN): 90.7 

2024-01-13 16:41:21,733 [trainer.py] => All params: 171816392
2024-01-13 16:41:21,734 [trainer.py] => Trainable params: 122980
2024-01-13 16:41:21,734 [l2p_self_training.py] => Learning on 10-20
2024-01-13 16:41:21,788 [l2p_self_training.py] => train dataset length: 250
Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95: 100%|██████████████████████████████████████████████████| 5/5 [00:24<00:00,  4.96s/it]
2024-01-13 16:41:46,570 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95
2024-01-13 16:41:46,572 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:42:02,705 [l2p_self_training.py] => 1541 unlabeled samples will be pseudo labeled
2024-01-13 16:42:02,706 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:42:02,707 [toolkit.py] => Pseudo Accuracy: 0.9565217391304348
2024-01-13 16:42:02,710 [l2p_self_training.py] => train dataset length: 1791
Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60: 100%|███████████████████████████████████████████████████| 5/5 [01:33<00:00, 18.73s/it]
2024-01-13 16:43:36,344 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60
2024-01-13 16:43:36,348 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:43:52,565 [l2p_self_training.py] => 1794 unlabeled samples will be pseudo labeled
2024-01-13 16:43:52,565 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:43:52,566 [toolkit.py] => Pseudo Accuracy: 0.9308807134894092
2024-01-13 16:43:52,569 [l2p_self_training.py] => train dataset length: 2044
Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50: 100%|███████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.01s/it]
2024-01-13 16:45:37,614 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50
2024-01-13 16:45:37,617 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:45:53,817 [l2p_self_training.py] => 1922 unlabeled samples will be pseudo labeled
2024-01-13 16:45:53,818 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:45:53,818 [toolkit.py] => Pseudo Accuracy: 0.9167533818938606
2024-01-13 16:46:05,689 [trainer.py] => No NME accuracy.
2024-01-13 16:46:05,689 [trainer.py] => CNN: {'total': 48.5, '00-09': 1.9, '10-19': 95.1, 'old': 1.9, 'new': 95.1}
2024-01-13 16:46:05,689 [trainer.py] => CNN top1 curve: [90.7, 48.5]
2024-01-13 16:46:05,689 [trainer.py] => CNN top5 curve: [99.2, 54.8]

Average Accuracy (CNN): 69.6
2024-01-13 16:46:05,689 [trainer.py] => Average Accuracy (CNN): 69.6 

2024-01-13 16:46:05,690 [trainer.py] => All params: 171816392
2024-01-13 16:46:05,691 [trainer.py] => Trainable params: 122980
2024-01-13 16:46:05,691 [l2p_self_training.py] => Learning on 20-30
2024-01-13 16:46:05,727 [l2p_self_training.py] => train dataset length: 250
Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00: 100%|██████████████████████████████████████████████████| 5/5 [00:30<00:00,  6.14s/it]
2024-01-13 16:46:36,449 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00
2024-01-13 16:46:36,452 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:46:54,140 [l2p_self_training.py] => 1838 unlabeled samples will be pseudo labeled
2024-01-13 16:46:54,141 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:46:54,141 [toolkit.py] => Pseudo Accuracy: 0.9613710554951034
2024-01-13 16:46:54,146 [l2p_self_training.py] => train dataset length: 2088
Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43: 100%|██████████████████████████████████████████████████| 5/5 [01:53<00:00, 22.62s/it]
2024-01-13 16:48:47,243 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43
2024-01-13 16:48:47,245 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:49:04,874 [l2p_self_training.py] => 2263 unlabeled samples will be pseudo labeled
2024-01-13 16:49:04,874 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:49:04,875 [toolkit.py] => Pseudo Accuracy: 0.8811312417145383
2024-01-13 16:49:04,879 [l2p_self_training.py] => train dataset length: 2513
Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97: 100%|██████████████████████████████████████████████████| 5/5 [02:12<00:00, 26.42s/it]
2024-01-13 16:51:16,961 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97
2024-01-13 16:51:16,963 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:51:34,567 [l2p_self_training.py] => 2305 unlabeled samples will be pseudo labeled
2024-01-13 16:51:34,567 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:51:34,568 [toolkit.py] => Pseudo Accuracy: 0.879826464208243
2024-01-13 16:51:52,203 [trainer.py] => No NME accuracy.
2024-01-13 16:51:52,203 [trainer.py] => CNN: {'total': 31.97, '00-09': 0.0, '10-19': 0.5, '20-29': 95.4, 'old': 0.25, 'new': 95.4}
2024-01-13 16:51:52,203 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97]
2024-01-13 16:51:52,203 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0]

Average Accuracy (CNN): 57.056666666666665
2024-01-13 16:51:52,203 [trainer.py] => Average Accuracy (CNN): 57.056666666666665 

2024-01-13 16:51:52,205 [trainer.py] => All params: 171816392
2024-01-13 16:51:52,206 [trainer.py] => Trainable params: 122980
2024-01-13 16:51:52,206 [l2p_self_training.py] => Learning on 30-40
2024-01-13 16:51:52,248 [l2p_self_training.py] => train dataset length: 250
Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18: 100%|██████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.21s/it]
2024-01-13 16:52:28,294 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18
2024-01-13 16:52:28,297 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:52:47,402 [l2p_self_training.py] => 1712 unlabeled samples will be pseudo labeled
2024-01-13 16:52:47,402 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:52:47,403 [toolkit.py] => Pseudo Accuracy: 0.927570093457944
2024-01-13 16:52:47,408 [l2p_self_training.py] => train dataset length: 1962
Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70: 100%|██████████████████████████████████████████████████| 5/5 [01:52<00:00, 22.58s/it]
2024-01-13 16:54:40,285 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70
2024-01-13 16:54:40,288 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:54:59,314 [l2p_self_training.py] => 2365 unlabeled samples will be pseudo labeled
2024-01-13 16:54:59,314 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:54:59,315 [toolkit.py] => Pseudo Accuracy: 0.8228329809725159
2024-01-13 16:54:59,319 [l2p_self_training.py] => train dataset length: 2615
Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30: 100%|██████████████████████████████████████████████████| 5/5 [02:21<00:00, 28.37s/it]
2024-01-13 16:57:21,159 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30
2024-01-13 16:57:21,161 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:57:40,154 [l2p_self_training.py] => 2407 unlabeled samples will be pseudo labeled
2024-01-13 16:57:40,155 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:57:40,155 [toolkit.py] => Pseudo Accuracy: 0.7947652679684254
2024-01-13 16:58:03,483 [trainer.py] => No NME accuracy.
2024-01-13 16:58:03,483 [trainer.py] => CNN: {'total': 32.3, '00-09': 0.0, '10-19': 0.0, '20-29': 39.6, '30-39': 89.6, 'old': 13.2, 'new': 89.6}
2024-01-13 16:58:03,483 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3]
2024-01-13 16:58:03,484 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83]

Average Accuracy (CNN): 50.86749999999999
2024-01-13 16:58:03,484 [trainer.py] => Average Accuracy (CNN): 50.86749999999999 

2024-01-13 16:58:03,485 [trainer.py] => All params: 171816392
2024-01-13 16:58:03,487 [trainer.py] => Trainable params: 122980
2024-01-13 16:58:03,487 [l2p_self_training.py] => Learning on 40-50
2024-01-13 16:58:03,540 [l2p_self_training.py] => train dataset length: 250
Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.085, Train_accy 92.80, Test_accy 27.60: 100%|██████████████████████████████████████████████████| 5/5 [00:42<00:00,  8.43s/it]
2024-01-13 16:58:45,690 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.085, Train_accy 92.80, Test_accy 27.60
2024-01-13 16:58:45,693 [l2p_self_training.py] => pseudo labeling start
2024-01-13 16:59:06,164 [l2p_self_training.py] => 1937 unlabeled samples will be pseudo labeled
2024-01-13 16:59:06,164 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 16:59:06,164 [toolkit.py] => Pseudo Accuracy: 0.9210118740320082
2024-01-13 16:59:06,168 [l2p_self_training.py] => train dataset length: 2187
Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.146, Train_accy 94.60, Test_accy 31.74: 100%|██████████████████████████████████████████████████| 5/5 [02:08<00:00, 25.68s/it]
2024-01-13 17:01:14,593 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.146, Train_accy 94.60, Test_accy 31.74
2024-01-13 17:01:14,597 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:01:35,109 [l2p_self_training.py] => 2615 unlabeled samples will be pseudo labeled
2024-01-13 17:01:35,109 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:01:35,110 [toolkit.py] => Pseudo Accuracy: 0.8409177820267686
2024-01-13 17:01:35,115 [l2p_self_training.py] => train dataset length: 2865
Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.077, Train_accy 92.71, Test_accy 29.54: 100%|██████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.73s/it]
2024-01-13 17:04:13,761 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.077, Train_accy 92.71, Test_accy 29.54
2024-01-13 17:04:13,765 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:04:34,289 [l2p_self_training.py] => 2697 unlabeled samples will be pseudo labeled
2024-01-13 17:04:34,289 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:04:34,290 [toolkit.py] => Pseudo Accuracy: 0.8075639599555061
2024-01-13 17:05:03,362 [trainer.py] => No NME accuracy.
2024-01-13 17:05:03,362 [trainer.py] => CNN: {'total': 29.54, '00-09': 0.0, '10-19': 0.0, '20-29': 17.0, '30-39': 33.0, '40-49': 97.7, 'old': 12.5, 'new': 97.7}
2024-01-13 17:05:03,362 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54]
2024-01-13 17:05:03,362 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86]

Average Accuracy (CNN): 46.60199999999999
2024-01-13 17:05:03,363 [trainer.py] => Average Accuracy (CNN): 46.60199999999999 

2024-01-13 17:05:03,364 [trainer.py] => All params: 171816392
2024-01-13 17:05:03,365 [trainer.py] => Trainable params: 122980
2024-01-13 17:05:03,365 [l2p_self_training.py] => Learning on 50-60
2024-01-13 17:05:03,417 [l2p_self_training.py] => train dataset length: 250
Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.036, Train_accy 90.00, Test_accy 28.17: 100%|██████████████████████████████████████████████████| 5/5 [00:47<00:00,  9.60s/it]
2024-01-13 17:05:51,416 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.036, Train_accy 90.00, Test_accy 28.17
2024-01-13 17:05:51,418 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:06:13,243 [l2p_self_training.py] => 1795 unlabeled samples will be pseudo labeled
2024-01-13 17:06:13,243 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:06:13,244 [toolkit.py] => Pseudo Accuracy: 0.9175487465181058
2024-01-13 17:06:13,249 [l2p_self_training.py] => train dataset length: 2045
Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.81, Test_accy 29.85: 100%|██████████████████████████████████████████████████| 5/5 [02:07<00:00, 25.53s/it]
2024-01-13 17:08:20,897 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.81, Test_accy 29.85
2024-01-13 17:08:20,900 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:08:42,750 [l2p_self_training.py] => 2532 unlabeled samples will be pseudo labeled
2024-01-13 17:08:42,751 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:08:42,752 [toolkit.py] => Pseudo Accuracy: 0.8135860979462876
2024-01-13 17:08:42,758 [l2p_self_training.py] => train dataset length: 2782
Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.066, Train_accy 92.42, Test_accy 29.10: 100%|██████████████████████████████████████████████████| 5/5 [02:40<00:00, 32.18s/it]
2024-01-13 17:11:23,641 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.066, Train_accy 92.42, Test_accy 29.10
2024-01-13 17:11:23,643 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:11:45,486 [l2p_self_training.py] => 2697 unlabeled samples will be pseudo labeled
2024-01-13 17:11:45,486 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:11:45,487 [toolkit.py] => Pseudo Accuracy: 0.7701149425287356
2024-01-13 17:12:20,253 [trainer.py] => No NME accuracy.
2024-01-13 17:12:20,253 [trainer.py] => CNN: {'total': 29.1, '00-09': 0.0, '10-19': 0.0, '20-29': 10.1, '30-39': 25.7, '40-49': 43.9, '50-59': 94.9, 'old': 15.94, 'new': 94.9}
2024-01-13 17:12:20,254 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1]
2024-01-13 17:12:20,254 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12]

Average Accuracy (CNN): 43.684999999999995
2024-01-13 17:12:20,254 [trainer.py] => Average Accuracy (CNN): 43.684999999999995 

2024-01-13 17:12:20,257 [trainer.py] => All params: 171816392
2024-01-13 17:12:20,260 [trainer.py] => Trainable params: 122980
2024-01-13 17:12:20,260 [l2p_self_training.py] => Learning on 60-70
2024-01-13 17:12:20,328 [l2p_self_training.py] => train dataset length: 250
Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.102, Train_accy 93.60, Test_accy 27.13: 100%|██████████████████████████████████████████████████| 5/5 [00:53<00:00, 10.65s/it]
2024-01-13 17:13:13,568 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.102, Train_accy 93.60, Test_accy 27.13
2024-01-13 17:13:13,571 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:13:36,864 [l2p_self_training.py] => 2074 unlabeled samples will be pseudo labeled
2024-01-13 17:13:36,864 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:13:36,865 [toolkit.py] => Pseudo Accuracy: 0.9387656702025072
2024-01-13 17:13:36,869 [l2p_self_training.py] => train dataset length: 2324
Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.93, Test_accy 30.16: 100%|██████████████████████████████████████████████████| 5/5 [02:26<00:00, 29.22s/it]
2024-01-13 17:16:02,954 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.93, Test_accy 30.16
2024-01-13 17:16:02,956 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:16:26,266 [l2p_self_training.py] => 2866 unlabeled samples will be pseudo labeled
2024-01-13 17:16:26,266 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:16:26,267 [toolkit.py] => Pseudo Accuracy: 0.8210048848569435
2024-01-13 17:16:26,274 [l2p_self_training.py] => train dataset length: 3116
Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.063, Train_accy 92.23, Test_accy 30.51: 100%|██████████████████████████████████████████████████| 5/5 [03:02<00:00, 36.43s/it]
2024-01-13 17:19:28,407 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.063, Train_accy 92.23, Test_accy 30.51
2024-01-13 17:19:28,409 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:19:51,817 [l2p_self_training.py] => 2931 unlabeled samples will be pseudo labeled
2024-01-13 17:19:51,817 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:19:51,818 [toolkit.py] => Pseudo Accuracy: 0.7922210849539406
2024-01-13 17:20:32,569 [trainer.py] => No NME accuracy.
2024-01-13 17:20:32,570 [trainer.py] => CNN: {'total': 30.51, '00-09': 0.0, '10-19': 0.0, '20-29': 16.4, '30-39': 22.9, '40-49': 31.0, '50-59': 45.1, '60-69': 98.2, 'old': 19.23, 'new': 98.2}
2024-01-13 17:20:32,570 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51]
2024-01-13 17:20:32,570 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73]

Average Accuracy (CNN): 41.802857142857135
2024-01-13 17:20:32,570 [trainer.py] => Average Accuracy (CNN): 41.802857142857135 

2024-01-13 17:20:32,572 [trainer.py] => All params: 171816392
2024-01-13 17:20:32,573 [trainer.py] => Trainable params: 122980
2024-01-13 17:20:32,573 [l2p_self_training.py] => Learning on 70-80
2024-01-13 17:20:32,635 [l2p_self_training.py] => train dataset length: 250
Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.019, Train_accy 90.80, Test_accy 24.54: 100%|██████████████████████████████████████████████████| 5/5 [00:59<00:00, 11.87s/it]
2024-01-13 17:21:32,003 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.019, Train_accy 90.80, Test_accy 24.54
2024-01-13 17:21:32,007 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:21:56,900 [l2p_self_training.py] => 1785 unlabeled samples will be pseudo labeled
2024-01-13 17:21:56,900 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:21:56,901 [toolkit.py] => Pseudo Accuracy: 0.8795518207282913
2024-01-13 17:21:56,905 [l2p_self_training.py] => train dataset length: 2035
Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.180, Train_accy 95.18, Test_accy 27.59: 100%|██████████████████████████████████████████████████| 5/5 [02:19<00:00, 27.94s/it]
2024-01-13 17:24:16,618 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.180, Train_accy 95.18, Test_accy 27.59
2024-01-13 17:24:16,620 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:24:41,605 [l2p_self_training.py] => 2886 unlabeled samples will be pseudo labeled
2024-01-13 17:24:41,605 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:24:41,606 [toolkit.py] => Pseudo Accuracy: 0.7366597366597366
2024-01-13 17:24:41,611 [l2p_self_training.py] => train dataset length: 3136
Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.039, Train_accy 91.04, Test_accy 27.49: 100%|██████████████████████████████████████████████████| 5/5 [03:10<00:00, 38.09s/it]
2024-01-13 17:27:52,075 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.039, Train_accy 91.04, Test_accy 27.49
2024-01-13 17:27:52,077 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:28:17,458 [l2p_self_training.py] => 3016 unlabeled samples will be pseudo labeled
2024-01-13 17:28:17,459 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:28:17,459 [toolkit.py] => Pseudo Accuracy: 0.7078912466843501
2024-01-13 17:29:04,373 [trainer.py] => No NME accuracy.
2024-01-13 17:29:04,373 [trainer.py] => CNN: {'total': 27.49, '00-09': 0.0, '10-19': 0.0, '20-29': 15.9, '30-39': 24.4, '40-49': 20.8, '50-59': 6.4, '60-69': 59.7, '70-79': 92.7, 'old': 18.17, 'new': 92.7}
2024-01-13 17:29:04,374 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49]
2024-01-13 17:29:04,374 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22]

Average Accuracy (CNN): 40.013749999999995
2024-01-13 17:29:04,374 [trainer.py] => Average Accuracy (CNN): 40.013749999999995 

2024-01-13 17:29:04,375 [trainer.py] => All params: 171816392
2024-01-13 17:29:04,376 [trainer.py] => Trainable params: 122980
2024-01-13 17:29:04,376 [l2p_self_training.py] => Learning on 80-90
2024-01-13 17:29:04,532 [l2p_self_training.py] => train dataset length: 250
Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.042, Train_accy 90.40, Test_accy 22.86: 100%|██████████████████████████████████████████████████| 5/5 [01:05<00:00, 13.16s/it]
2024-01-13 17:30:10,323 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.042, Train_accy 90.40, Test_accy 22.86
2024-01-13 17:30:10,325 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:30:36,707 [l2p_self_training.py] => 1985 unlabeled samples will be pseudo labeled
2024-01-13 17:30:36,707 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:30:36,708 [toolkit.py] => Pseudo Accuracy: 0.8937027707808565
2024-01-13 17:30:36,715 [l2p_self_training.py] => train dataset length: 2235
Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.116, Train_accy 94.18, Test_accy 24.93: 100%|██████████████████████████████████████████████████| 5/5 [02:34<00:00, 30.81s/it]
2024-01-13 17:33:10,742 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.116, Train_accy 94.18, Test_accy 24.93
2024-01-13 17:33:10,744 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:33:37,001 [l2p_self_training.py] => 2888 unlabeled samples will be pseudo labeled
2024-01-13 17:33:37,001 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:33:37,002 [toolkit.py] => Pseudo Accuracy: 0.7725069252077562
2024-01-13 17:33:37,008 [l2p_self_training.py] => train dataset length: 3138
Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.27, Test_accy 23.64: 100%|██████████████████████████████████████████████████| 5/5 [03:14<00:00, 38.85s/it]
2024-01-13 17:36:51,264 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.27, Test_accy 23.64
2024-01-13 17:36:51,268 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:37:17,441 [l2p_self_training.py] => 3082 unlabeled samples will be pseudo labeled
2024-01-13 17:37:17,442 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:37:17,443 [toolkit.py] => Pseudo Accuracy: 0.7196625567813109
2024-01-13 17:38:09,611 [trainer.py] => No NME accuracy.
2024-01-13 17:38:09,612 [trainer.py] => CNN: {'total': 23.64, '00-09': 0.0, '10-19': 0.0, '20-29': 10.3, '30-39': 20.5, '40-49': 11.8, '50-59': 2.0, '60-69': 36.6, '70-79': 35.3, '80-89': 96.3, 'old': 14.56, 'new': 96.3}
2024-01-13 17:38:09,612 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49, 23.64]
2024-01-13 17:38:09,612 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22, 30.0]

Average Accuracy (CNN): 38.194444444444436
2024-01-13 17:38:09,612 [trainer.py] => Average Accuracy (CNN): 38.194444444444436 

2024-01-13 17:38:09,614 [trainer.py] => All params: 171816392
2024-01-13 17:38:09,615 [trainer.py] => Trainable params: 122980
2024-01-13 17:38:09,615 [l2p_self_training.py] => Learning on 90-100
2024-01-13 17:38:09,766 [l2p_self_training.py] => train dataset length: 250
Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.020, Train_accy 90.00, Test_accy 23.96: 100%|██████████████████████████████████████████████████| 5/5 [01:10<00:00, 14.09s/it]
2024-01-13 17:39:20,225 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.020, Train_accy 90.00, Test_accy 23.96
2024-01-13 17:39:20,229 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:39:47,896 [l2p_self_training.py] => 1943 unlabeled samples will be pseudo labeled
2024-01-13 17:39:47,896 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:39:47,897 [toolkit.py] => Pseudo Accuracy: 0.9186824498198661
2024-01-13 17:39:47,906 [l2p_self_training.py] => train dataset length: 2193
Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.16, Test_accy 25.88: 100%|██████████████████████████████████████████████████| 5/5 [02:38<00:00, 31.75s/it]
2024-01-13 17:42:26,652 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.118, Train_accy 93.16, Test_accy 25.88
2024-01-13 17:42:26,655 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:42:54,299 [l2p_self_training.py] => 2832 unlabeled samples will be pseudo labeled
2024-01-13 17:42:54,299 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:42:54,300 [toolkit.py] => Pseudo Accuracy: 0.7874293785310734
2024-01-13 17:42:54,305 [l2p_self_training.py] => train dataset length: 3082
Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.30, Test_accy 25.50: 100%|██████████████████████████████████████████████████| 5/5 [03:17<00:00, 39.48s/it]
2024-01-13 17:46:11,731 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.025, Train_accy 91.30, Test_accy 25.50
2024-01-13 17:46:11,733 [l2p_self_training.py] => pseudo labeling start
2024-01-13 17:46:39,313 [l2p_self_training.py] => 3086 unlabeled samples will be pseudo labeled
2024-01-13 17:46:39,314 [l2p_self_training.py] => pseudo labeling finish
2024-01-13 17:46:39,315 [toolkit.py] => Pseudo Accuracy: 0.7300712896953986
2024-01-13 17:47:37,385 [trainer.py] => No NME accuracy.
2024-01-13 17:47:37,385 [trainer.py] => CNN: {'total': 25.5, '00-09': 0.0, '10-19': 0.0, '20-29': 13.6, '30-39': 23.2, '40-49': 12.6, '50-59': 1.9, '60-69': 25.5, '70-79': 9.5, '80-89': 73.7, '90-99': 95.0, 'old': 17.78, 'new': 95.0}
2024-01-13 17:47:37,385 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3, 29.54, 29.1, 30.51, 27.49, 23.64, 25.5]
2024-01-13 17:47:37,385 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83, 37.86, 37.12, 35.73, 34.22, 30.0, 30.6]

Average Accuracy (CNN): 36.925
2024-01-13 17:47:37,385 [trainer.py] => Average Accuracy (CNN): 36.925 

######################################################################################
======================================================================================
######################################################################################

(lhz-torch-2.0) lhz@csgpu-SYS-4029GP-TRT:~/code/LAMDA-PILOT$ python main.py --config=exps/l2p_self_training.json
2024-01-18 10:18:25,084 [trainer.py] => config: exps/l2p_self_training.json
2024-01-18 10:18:25,131 [trainer.py] => prefix:  
2024-01-18 10:18:25,132 [trainer.py] => dataset: cifar224
2024-01-18 10:18:25,132 [trainer.py] => memory_size: 0
2024-01-18 10:18:25,132 [trainer.py] => memory_per_class: 0
2024-01-18 10:18:25,132 [trainer.py] => fixed_memory: False
2024-01-18 10:18:25,132 [trainer.py] => shuffle: True
2024-01-18 10:18:25,132 [trainer.py] => init_cls: 10
2024-01-18 10:18:25,132 [trainer.py] => increment: 10
2024-01-18 10:18:25,132 [trainer.py] => model_name: l2p_self_training
2024-01-18 10:18:25,133 [trainer.py] => backbone_type: vit_base_patch16_224_l2p
2024-01-18 10:18:25,133 [trainer.py] => get_original_backbone: True
2024-01-18 10:18:25,133 [trainer.py] => device: [device(type='cuda', index=5)]
2024-01-18 10:18:25,133 [trainer.py] => seed: 1993
2024-01-18 10:18:25,133 [trainer.py] => tuned_epoch: 5
2024-01-18 10:18:25,133 [trainer.py] => init_lr: 0.001875
2024-01-18 10:18:25,133 [trainer.py] => batch_size: 16
2024-01-18 10:18:25,133 [trainer.py] => weight_decay: 0
2024-01-18 10:18:25,134 [trainer.py] => min_lr: 1e-05
2024-01-18 10:18:25,134 [trainer.py] => optimizer: adam
2024-01-18 10:18:25,134 [trainer.py] => scheduler: constant
2024-01-18 10:18:25,134 [trainer.py] => reinit_optimizer: True
2024-01-18 10:18:25,134 [trainer.py] => global_pool: token
2024-01-18 10:18:25,134 [trainer.py] => head_type: prompt
2024-01-18 10:18:25,134 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2024-01-18 10:18:25,134 [trainer.py] => pretrained: True
2024-01-18 10:18:25,134 [trainer.py] => drop: 0.0
2024-01-18 10:18:25,135 [trainer.py] => drop_path: 0.0
2024-01-18 10:18:25,135 [trainer.py] => prompt_pool: True
2024-01-18 10:18:25,135 [trainer.py] => pool_size: 10
2024-01-18 10:18:25,135 [trainer.py] => length: 5
2024-01-18 10:18:25,135 [trainer.py] => top_k: 5
2024-01-18 10:18:25,135 [trainer.py] => initializer: uniform
2024-01-18 10:18:25,135 [trainer.py] => prompt_key: True
2024-01-18 10:18:25,135 [trainer.py] => prompt_key_init: uniform
2024-01-18 10:18:25,136 [trainer.py] => use_prompt_mask: False
2024-01-18 10:18:25,136 [trainer.py] => shared_prompt_pool: False
2024-01-18 10:18:25,136 [trainer.py] => shared_prompt_key: False
2024-01-18 10:18:25,136 [trainer.py] => batchwise_prompt: True
2024-01-18 10:18:25,136 [trainer.py] => embedding_key: cls
2024-01-18 10:18:25,136 [trainer.py] => predefined_key: 
2024-01-18 10:18:25,136 [trainer.py] => pull_constraint: True
2024-01-18 10:18:25,136 [trainer.py] => pull_constraint_coeff: 0.1
2024-01-18 10:18:25,136 [trainer.py] => semi_supervised_mode: True
2024-01-18 10:18:25,137 [trainer.py] => labeled_ratio: 0.05
2024-01-18 10:18:25,137 [trainer.py] => unlabeled_data_distribution_mode: previous_oot
2024-01-18 10:18:25,137 [trainer.py] => confidence_threshold: 0.9
2024-01-18 10:18:25,137 [trainer.py] => max_self_training_iteration: 3
Files already downloaded and verified
Files already downloaded and verified
2024-01-18 10:18:27,063 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-01-18 10:18:28,754 [vision_transformer_l2p.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2024-01-18 10:18:28,755 [vision_transformer_l2p.py] => Position embedding grid-size from [14, 14] to (14, 14)
2024-01-18 10:18:30,989 [l2p_self_training.py] => 85,940,836 model total parameters.
2024-01-18 10:18:30,990 [l2p_self_training.py] => 122,980 model training parameters.
2024-01-18 10:18:30,990 [l2p_self_training.py] => prompt.prompt: 38400
2024-01-18 10:18:30,990 [l2p_self_training.py] => prompt.prompt_key: 7680
2024-01-18 10:18:30,990 [l2p_self_training.py] => head.weight: 76800
2024-01-18 10:18:30,990 [l2p_self_training.py] => head.bias: 100
2024-01-18 10:18:30,991 [trainer.py] => All params: 171816392
2024-01-18 10:18:30,992 [trainer.py] => Trainable params: 122980
2024-01-18 10:18:30,992 [l2p_self_training.py] => Learning on 0-10
2024-01-18 10:18:31,813 [l2p_self_training.py] => train dataset length: 250
Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50: 100%|███████████████████████████████████████████████████| 5/5 [00:19<00:00,  3.93s/it]
2024-01-18 10:18:51,484 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50
2024-01-18 10:18:51,488 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:19:06,150 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[5 6 1 1 1 1 1 7 1 3 5 9 5 1 7 1 1 7 4 1 7 9]
2024-01-18 10:19:06,151 [l2p_self_training.py] => wrong labeled samples' true label:
[7 0 0 7 9 9 3 8 0 2 7 4 8 0 8 0 3 2 1 6 5 4]
2024-01-18 10:19:06,152 [l2p_self_training.py] => 1038 unlabeled samples will be pseudo labeled
2024-01-18 10:19:06,152 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:19:06,152 [toolkit.py] => Pseudo Accuracy: 0.9788053949903661
2024-01-18 10:19:06,158 [l2p_self_training.py] => train dataset length: 1288
Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70: 100%|███████████████████████████████████████████████████| 5/5 [01:05<00:00, 13.11s/it]
2024-01-18 10:20:11,686 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70
2024-01-18 10:20:11,689 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:20:26,492 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[3 6 3 3 8 1 8 3 1 5 8 8 3 3 3 5 9 8 5 5 3 7 1 3 1 3 9 8 1 9 3 5 8 3 5 3 1
 3 8 1 8 1 6 3 8 3 8 3 3 1 8 6 8 1 9 3 3 3 3 8 1 1 6 8 1 5 1 8 9 3 3 3 5 6
 1 3 1 0 5 3 1 2]
2024-01-18 10:20:26,493 [l2p_self_training.py] => wrong labeled samples' true label:
[8 3 5 2 4 0 2 2 0 7 7 7 5 5 5 7 6 2 7 1 7 6 0 6 6 2 4 7 4 4 5 7 2 6 7 2 6
 9 7 0 6 7 7 7 7 7 7 2 2 2 7 0 5 0 4 6 2 6 2 3 9 6 0 2 4 9 9 9 4 7 2 8 7 0
 9 2 0 3 7 2 0 1]
2024-01-18 10:20:26,494 [l2p_self_training.py] => 1668 unlabeled samples will be pseudo labeled
2024-01-18 10:20:26,494 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:20:26,494 [toolkit.py] => Pseudo Accuracy: 0.9508393285371702
2024-01-18 10:20:26,498 [l2p_self_training.py] => train dataset length: 1918
Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70: 100%|███████████████████████████████████████████████████| 5/5 [01:34<00:00, 18.82s/it]
2024-01-18 10:22:00,609 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70
2024-01-18 10:22:00,612 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:22:15,483 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[3 6 8 8 1 1 1 3 3 6 8 3 6 6 1 1 1 5 8 0 3 5 9 2 5 6 3 9 6 1 9 7 3 3 8 2 9
 1 3 1 5 9 1 9 2 1 1 1 0 8 3 1 2 1 1 6 8 5 3 9 6 9 5 5 8 1 9 3 9 1 1 1 8 2
 1 8 6 3]
2024-01-18 10:22:15,484 [l2p_self_training.py] => wrong labeled samples' true label:
[2 0 7 1 0 0 3 2 7 7 9 2 0 0 4 0 0 8 7 4 5 9 7 7 3 0 2 0 9 4 1 0 2 5 7 8 4
 0 6 6 7 6 0 4 6 4 4 8 3 7 5 0 5 9 4 0 7 1 5 4 0 4 7 7 7 0 4 5 4 0 0 3 7 3
 0 4 0 2]
2024-01-18 10:22:15,485 [l2p_self_training.py] => 1679 unlabeled samples will be pseudo labeled
2024-01-18 10:22:15,485 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:22:15,485 [toolkit.py] => Pseudo Accuracy: 0.9535437760571769
2024-01-18 10:22:21,698 [trainer.py] => No NME accuracy.
2024-01-18 10:22:21,698 [trainer.py] => CNN: {'total': 90.7, '00-09': 90.7, 'old': 0, 'new': 90.7}
2024-01-18 10:22:21,698 [trainer.py] => CNN top1 curve: [90.7]
2024-01-18 10:22:21,698 [trainer.py] => CNN top5 curve: [99.2]

Average Accuracy (CNN): 90.7
2024-01-18 10:22:21,698 [trainer.py] => Average Accuracy (CNN): 90.7 

2024-01-18 10:22:21,700 [trainer.py] => All params: 171816392
2024-01-18 10:22:21,701 [trainer.py] => Trainable params: 122980
2024-01-18 10:22:21,701 [l2p_self_training.py] => Learning on 10-20
2024-01-18 10:22:21,731 [l2p_self_training.py] => train dataset length: 250
Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95: 100%|██████████████████████████████████████████████████| 5/5 [00:25<00:00,  5.07s/it]
2024-01-18 10:22:47,103 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.002, Train_accy 91.20, Test_accy 47.95
2024-01-18 10:22:47,105 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:23:03,398 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[16 14 10 17 11 17 18 14 17 15 17 11 17 10 18 11 17 18 17 10 17 17 10 15
 17 17 15 14 17 18 17 14 18 17 10 15 17 14 17 10 17 18 15 11 11 10 11 17
 17 11 15 18 17 10 11 10 18 15 17 17 10 17 17 18 14 16 11]
2024-01-18 10:23:03,398 [l2p_self_training.py] => wrong labeled samples' true label:
[ 2 12  1 12  6 11 12  8 19 10  8  3 12  5 19  6 14 17  4 16  7 19  5 10
  7 19 13 16  4 19 16 12 12 12  1 10 14 17 19  1  8 12 13  6  6  1  6 12
 12 10 10 12 19  9  6 15 12 10 19 19  9 19 12 12 18 14  6]
2024-01-18 10:23:03,399 [l2p_self_training.py] => 1541 unlabeled samples will be pseudo labeled
2024-01-18 10:23:03,399 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:23:03,399 [toolkit.py] => Pseudo Accuracy: 0.9565217391304348
2024-01-18 10:23:03,402 [l2p_self_training.py] => train dataset length: 1791
Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60: 100%|███████████████████████████████████████████████████| 5/5 [01:34<00:00, 18.86s/it]
2024-01-18 10:24:37,728 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.037, Train_accy 89.06, Test_accy 47.60
2024-01-18 10:24:37,732 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:24:54,051 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[11 10 10 14 10 14 10 10 11 11 11 10 15 12 11 10 18 17 10 10 10 10 14 14
 15 14 16 12 10 16 17 10 17 12 10 11 14 10 10 13 11 14 15 10 14 14 10 10
 15 17 11 14 14 11 17 16 10 10 11 11 10 14 12 12 19 12 14 11 12 14 12 17
 11 14 11 14 10 10 11 11 14 10 12 12 12 10 15 14 14 16 12 15 12 18 10 11
 11 14 11 15 12 10 17 14 14 15 12 14 14 15 11 17 14 10 10 14 12 11 18 17
 17 16 16 14]
2024-01-18 10:24:54,053 [l2p_self_training.py] => wrong labeled samples' true label:
[ 6  1  1 12  1 16  1 15  6  6  6  5 10 17  6  1 19 19  5  5  1  1 19 16
 10 19 13 17  1  3 19  1 12  7  9  6 12  9  9 15 15 17 11  1 12  8  3  1
  0 12  6 16 12  6 19  2 15  5  6  6  1  4 14 17  8 17 17  0 16 12  8 19
  6 17  6 19  5  1  6  6  8  9 14 17 14  5 10 19 16 19 17 10 19 12  3 10
  6  8  3  2  7  1  7 19  5 10 14  7 17 10  3  7 16  5  1 10 18  6 12  2
 12  8 14 19]
2024-01-18 10:24:54,053 [l2p_self_training.py] => 1794 unlabeled samples will be pseudo labeled
2024-01-18 10:24:54,053 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:24:54,054 [toolkit.py] => Pseudo Accuracy: 0.9308807134894092
2024-01-18 10:24:54,058 [l2p_self_training.py] => train dataset length: 2044
Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50: 100%|███████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.15s/it]
2024-01-18 10:26:39,822 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.010, Train_accy 90.02, Test_accy 48.50
2024-01-18 10:26:39,825 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:26:56,071 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[12 14 10 10 10 17 12 10 10 14 10 11 12 12 10 10 19 10 12 10 14 11 11 10
 17 10 10 18 11 11 10 17 15 10 10 10 12 12 17 12 10 13 17 10 12 10 18 12
 10 10 10 12 12 13 10 17 11 10 10 14 12 12 10 10 10 11 10 12 12 10 10 17
 10 17 10 11 17 14 11 10 12 16 12 12 15 12 17 12 14 12 17 10 17 11 12 14
 12 11 10 14 15 10 11 17 12 18 17 12 11 11 10 15 10 11 13 10 10 15 10 10
 10 13 10 10 10 17 10 11 17 17 10 11 10 14 18 10 10 10 10 11 11 12 15 11
 17 15 11 12 12 17 14 11 11 11 17 12 10 10 10 11]
2024-01-18 10:26:56,072 [l2p_self_training.py] => wrong labeled samples' true label:
[17 16  1 15  1  7 18  9  1  8  1  6 14  7  3 15  7  5 14  1 16  0  7  1
 19  1  9 14  3  6 12 19 10  4 15  5 14 19 18 14  3 17  5  5 14  5 19 14
  9  1  1 14 16 15  1  8  6  1  9 17 18  3  3  1  5  6  9 17 14  9  9 19
  9  8  7  0 14 19 17  1 14  3 19 14  2 17 19 14 10  8 18  5 19  0 17 12
 14  6  3  8 10  5  0 12 17 19  8 13  6  0  9 10 11  6 11  1  5 10  3  1
  3  0  5  9  9 18  4  6 19 19  5  6  3 16 10  3  5  9  1  6  6 17 10  9
 19 10  3  8 17 12 12  6  6  6 19 16  1  1  1  0]
2024-01-18 10:26:56,072 [l2p_self_training.py] => 1922 unlabeled samples will be pseudo labeled
2024-01-18 10:26:56,072 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:26:56,073 [toolkit.py] => Pseudo Accuracy: 0.9167533818938606
2024-01-18 10:27:07,993 [trainer.py] => No NME accuracy.
2024-01-18 10:27:07,993 [trainer.py] => CNN: {'total': 48.5, '00-09': 1.9, '10-19': 95.1, 'old': 1.9, 'new': 95.1}
2024-01-18 10:27:07,993 [trainer.py] => CNN top1 curve: [90.7, 48.5]
2024-01-18 10:27:07,993 [trainer.py] => CNN top5 curve: [99.2, 54.8]

Average Accuracy (CNN): 69.6
2024-01-18 10:27:07,994 [trainer.py] => Average Accuracy (CNN): 69.6 

2024-01-18 10:27:07,995 [trainer.py] => All params: 171816392
2024-01-18 10:27:07,997 [trainer.py] => Trainable params: 122980
2024-01-18 10:27:07,997 [l2p_self_training.py] => Learning on 20-30
2024-01-18 10:27:08,047 [l2p_self_training.py] => train dataset length: 250
Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00: 100%|██████████████████████████████████████████████████| 5/5 [00:31<00:00,  6.24s/it]
2024-01-18 10:27:39,245 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.091, Train_accy 92.00, Test_accy 34.00
2024-01-18 10:27:39,247 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:27:57,099 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[21 28 28 27 27 25 27 28 20 21 27 25 21 21 21 27 27 21 21 27 27 21 25 24
 27 27 23 21 20 28 26 27 27 27 23 20 27 23 20 28 20 21 24 21 24 27 24 27
 25 27 28 26 27 28 21 21 21 27 28 20 25 27 20 25 20 25 22 27 21 25 27]
2024-01-18 10:27:57,101 [l2p_self_training.py] => wrong labeled samples' true label:
[13 10  5  8  7 18  7 10 15 13  8 12  1 13 13  8  7 13 13 17  7 13 19  1
  8  8 22 13 24  5 24  7 17  8 16 11  8 21 11 10 24 13  6 13 20 19  6  8
 19  8 10  9  7 10 13 13 13 17 10 24 12  7  6 12  6 12 24 19 13 23 17]
2024-01-18 10:27:57,102 [l2p_self_training.py] => 1838 unlabeled samples will be pseudo labeled
2024-01-18 10:27:57,102 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:27:57,102 [toolkit.py] => Pseudo Accuracy: 0.9613710554951034
2024-01-18 10:27:57,105 [l2p_self_training.py] => train dataset length: 2088
Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43: 100%|██████████████████████████████████████████████████| 5/5 [01:54<00:00, 22.83s/it]
2024-01-18 10:29:51,255 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.111, Train_accy 93.87, Test_accy 32.43
2024-01-18 10:29:51,259 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:30:09,017 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[26 24 21 20 27 27 20 25 27 25 27 27 27 25 27 20 24 27 25 25 27 27 25 20
 20 24 26 27 26 27 21 27 26 28 27 27 20 25 27 23 27 21 24 20 20 20 21 27
 27 27 26 26 20 27 21 28 28 22 27 26 25 27 27 25 21 21 25 21 24 23 25 27
 25 20 21 27 27 20 24 20 27 21 20 25 23 21 27 20 27 27 21 20 27 25 27 27
 27 27 25 20 20 27 20 24 27 27 27 23 23 27 25 27 20 21 27 25 27 27 20 27
 27 27 25 27 20 25 27 20 24 24 24 29 27 21 27 25 27 24 25 25 27 20 26 21
 27 27 21 27 20 26 20 26 27 27 27 21 26 20 20 27 21 27 20 27 25 23 28 27
 27 25 21 20 27 24 26 27 20 25 27 25 20 27 25 27 27 21 20 27 25 25 25 25
 25 20 20 21 20 27 27 25 27 21 23 27 25 21 21 20 21 27 27 27 27 25 21 20
 27 25 27 25 20 27 25 26 25 28 20 22 25 20 27 27 28 25 25 27 22 27 25 21
 21 27 27 25 20 28 27 25 24 27 27 25 24 20 25 25 27 20 25 25 27 24 27 20
 25 29 26 25 20]
2024-01-18 10:30:09,020 [l2p_self_training.py] => wrong labeled samples' true label:
[ 9 20 13 11 26 18 25 22 17 12 19  2  7 12  2  6  6 17 12 14 22 22 18 24
 24 26 20 22  9  8 23  8  9 10 25 19 10 12 12 10 25 13  4  6 24 11 29  2
 19  7  9 24  6  7 23 10 10 16 14  9 12  4  7 19 13 13 16 13  6  0 18 17
 18  3 13 25 23  5  1 11 28 23 25 22 10 13  8 11 25  7 13 11 17 18  8  7
  8 19 18  0  5 22 11  6  5  7 19 22 16  8 18 14 24 13 17 12 22  4 11 17
  8  8 18  8 11 19  7 24  2 20  4 23  7 13 19  7 19 25 22 18  2 11  9 10
 17  2 10  7  6  0  3  9 12 17 14 13  0  3  6 16 13 17 24 17 19 28 10  7
 19 19 13 24  7  3  0  7  6 27  8 19  6  8 14  8 17 13  6 17 18 18 12 12
 23 11 24 13 10 22  8 18 17 13 21 14 18 13 13 11 13  8 25 18 17 27 13 24
 17 16  8 12 11 14 12  9 12  5  3 14 18 11 17 17 11 18 12  8 14 14 27 13
 13  7 17 18 11  5  8 18  1  8  7 23  1  3 12 19 14 11 12 19  8  3 14  6
 12 22  9 12 24]
2024-01-18 10:30:09,021 [l2p_self_training.py] => 2263 unlabeled samples will be pseudo labeled
2024-01-18 10:30:09,021 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:30:09,021 [toolkit.py] => Pseudo Accuracy: 0.8811312417145383
2024-01-18 10:30:09,025 [l2p_self_training.py] => train dataset length: 2513
Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97: 100%|██████████████████████████████████████████████████| 5/5 [02:12<00:00, 26.55s/it]
2024-01-18 10:32:21,777 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.028, Train_accy 90.65, Test_accy 31.97
2024-01-18 10:32:21,779 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:32:39,525 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[24 21 25 20 20 24 23 24 22 27 24 21 27 23 25 21 21 25 24 24 25 27 25 27
 27 24 26 23 21 28 24 27 23 27 20 27 26 20 27 28 27 26 27 27 20 25 26 27
 27 20 27 27 25 27 27 20 25 27 25 24 21 23 27 26 21 24 27 21 24 21 21 24
 26 27 27 20 25 24 24 27 25 27 27 20 27 20 25 27 27 27 27 23 27 27 23 27
 24 23 26 20 24 24 22 25 28 27 24 27 27 28 27 20 27 27 22 28 20 27 24 28
 27 26 23 25 20 27 24 27 26 21 20 20 27 20 27 27 24 25 24 26 24 27 20 20
 25 27 20 25 24 27 26 27 20 20 24 27 27 24 25 24 25 27 25 25 26 20 20 23
 27 24 20 27 20 27 26 28 27 23 24 27 24 27 24 21 27 24 26 26 28 20 21 27
 24 25 25 20 28 27 25 23 20 25 20 22 27 27 25 27 24 25 20 27 20 27 24 27
 20 21 24 27 27 27 27 21 25 25 21 25 20 27 29 27 25 24 25 20 25 21 20 25
 21 23 25 20 23 24 28 25 27 24 24 21 26 26 22 27 27 21 20 22 25 24 27 20
 27 26 27 20 27 24 28 27 28 25 25 20 28]
2024-01-18 10:32:39,527 [l2p_self_training.py] => wrong labeled samples' true label:
[ 4 13 12  6  3  1 22 25 14 14  1 13 25 21 12 13 13 12 26 26 12  8 12  2
  8  2  9 28 13 10  1 17 16  8 11  7  9 16 17 16  8  9  7  7  6 18  0 19
  2  3 19 17 12  7 10 11 18 14 12 20 13 21 22  9 13  4 17 13  1 13 13 25
  9  8  7 11 18 15 26 14 18 19 17 24  8  6 18 14  8 14 19 16 22 17 22 17
  2 10  9 24  1  4 16 18 10  7  1  8  8  5  8 11  4 19 25  5  3  7  6 10
  8  0 21 18 24  8  3  4  9 13 16  3  2 11  7  2  4 18 25  9  1 17 11  6
 18 17 11 19 25  8  0  2  6 11  6  7  2  4 18  1 18 14 19 22  9 11  3 27
  2 20 11  7  6  5  9 15 22 21  4 17 26 14  6  1  7  1  9  9  5  3 13 19
  3 18 12 24 10  8 18  9 11 12 10 14 22 17 18  2 26  5  6 22 11  3  1  8
 11 13 20 19  8 17  2 13 18 12 13 19 11 17 23 17 18  4 18  6 18 13 11 19
 13 21 27  6 16  1 10 12 22 26 20  1 12  0 27 22  8  1 11 16 12  4 14 25
  7  9 13 10  7  9 10  8 10  7 12  6 27]
2024-01-18 10:32:39,527 [l2p_self_training.py] => 2305 unlabeled samples will be pseudo labeled
2024-01-18 10:32:39,527 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:32:39,528 [toolkit.py] => Pseudo Accuracy: 0.879826464208243
2024-01-18 10:32:57,657 [trainer.py] => No NME accuracy.
2024-01-18 10:32:57,658 [trainer.py] => CNN: {'total': 31.97, '00-09': 0.0, '10-19': 0.5, '20-29': 95.4, 'old': 0.25, 'new': 95.4}
2024-01-18 10:32:57,658 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97]
2024-01-18 10:32:57,658 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0]

Average Accuracy (CNN): 57.056666666666665
2024-01-18 10:32:57,658 [trainer.py] => Average Accuracy (CNN): 57.056666666666665 

2024-01-18 10:32:57,659 [trainer.py] => All params: 171816392
2024-01-18 10:32:57,660 [trainer.py] => Trainable params: 122980
2024-01-18 10:32:57,660 [l2p_self_training.py] => Learning on 30-40
2024-01-18 10:32:57,704 [l2p_self_training.py] => train dataset length: 250
Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18: 100%|██████████████████████████████████████████████████| 5/5 [00:37<00:00,  7.45s/it]
2024-01-18 10:33:34,942 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.057, Train_accy 92.80, Test_accy 31.18
2024-01-18 10:33:34,944 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:33:54,136 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[35 35 35 30 37 38 32 32 38 32 37 39 31 30 32 30 38 35 35 35 32 31 38 32
 30 30 36 35 30 39 38 39 30 37 31 37 30 37 30 30 35 31 30 30 37 32 39 39
 39 37 30 31 30 38 37 31 31 36 32 35 35 35 30 30 38 30 30 39 35 35 37 30
 33 39 33 35 39 32 30 30 30 32 32 37 37 38 37 35 35 39 35 32 38 39 32 30
 38 32 38 35 39 35 35 38 35 37 37 37 35 38 35 32 39 39 39 38 36 35 30 35
 35 30 30 31]
2024-01-18 10:33:54,137 [l2p_self_training.py] => wrong labeled samples' true label:
[ 0  4  4 20 15 18  8 16 25 16 15  2  6 20 16 20 18  0 24  0 16 30 18 16
 20 20 29  4 20  2 18  2 20 15  6 15 20 15 31 24  4 30  3 10 15 14  8 19
 17 15 20  6 20 12 15  6  6 13 16  4  0  9 20 20 18 20 20 32  4  1 15 31
 34  2 34 30  8 16 20 20  5 16 16 15 31 12 15  4  0 19  4 16 25  8 16 20
 25 39 25 30 19  4  4 18  1 28 15 15  0 14  0 16  2 19  2 18 29  4 20 31
  4 20 31 30]
2024-01-18 10:33:54,138 [l2p_self_training.py] => 1712 unlabeled samples will be pseudo labeled
2024-01-18 10:33:54,138 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:33:54,138 [toolkit.py] => Pseudo Accuracy: 0.927570093457944
2024-01-18 10:33:54,141 [l2p_self_training.py] => train dataset length: 1962
Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70: 100%|██████████████████████████████████████████████████| 5/5 [01:53<00:00, 22.65s/it]
2024-01-18 10:35:47,408 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.130, Train_accy 94.04, Test_accy 32.70
2024-01-18 10:35:47,410 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:36:06,613 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[30 39 35 30 36 31 30 35 39 32 39 38 37 39 39 35 35 33 33 30 30 39 30 30
 39 37 32 37 33 38 32 37 30 30 30 39 38 35 38 30 35 30 30 38 38 38 35 30
 30 30 30 38 30 38 30 35 28 38 39 30 30 39 30 30 30 39 37 32 39 33 37 33
 30 30 35 30 37 30 30 28 39 31 39 39 30 39 35 35 38 39 30 21 39 30 38 33
 32 30 30 35 38 38 38 30 31 38 39 35 35 38 30 35 30 38 39 31 35 30 30 38
 30 30 37 30 38 39 38 35 37 30 35 32 38 37 37 31 38 39 30 30 30 30 30 38
 33 39 37 35 38 39 30 30 32 35 30 38 30 30 38 38 30 35 30 38 32 39 30 30
 33 39 30 38 39 39 30 32 35 37 38 37 30 30 35 38 39 35 38 39 35 35 37 39
 33 30 38 30 32 38 38 37 39 38 30 38 35 30 30 30 38 30 30 39 35 30 35 35
 30 30 39 30 35 37 30 39 38 38 31 39 30 36 39 39 35 32 37 30 30 33 30 30
 33 38 35 38 35 30 39 38 30 30 30 39 37 38 30 35 30 30 33 38 35 39 31 38
 38 30 35 38 39 31 38 39 33 38 30 30 34 38 38 35 35 39 38 39 38 28 30 32
 38 35 30 39 30 30 35 39 30 30 33 39 31 30 30 30 35 37 37 38 30 39 39 32
 39 39 35 30 39 35 38 39 35 33 30 39 30 39 35 38 35 38 39 39 35 39 39 35
 30 37 32 39 30 33 38 35 28 30 30 39 30 39 38 39 39 39 30 38 39 39 30 39
 33 38 33 38 31 33 35 39 30 30 31 30 30 35 35 32 30 39 30 36 30 33 39 39
 33 30 32 39 32 38 39 32 35 34 30 32 37 30 39 39 30 35 39 39 30 37 35 30
 37 30 39 34 30 30 38 35 38 38 38]
2024-01-18 10:36:06,616 [l2p_self_training.py] => wrong labeled samples' true label:
[31 16 36 31 29  6  3  0 17  8  8 14 15  7  2  4  3 21 36 20 31 19 31 11
 19 15 16 15 13 12 14 15 24 11 31  8 25  0 25 11  1 32  9 25 18 22  4 20
 20  5 31 18 31 18 31  4 10 18  7 31 20  8 31 31 31 23 15 36 19 34 15 35
 10  6  1 20  3 31 31 37 32 30  7 27 20  2  4  1 19 19 31 13  7 31 12 13
 16 31 20  0 25 18 16 31  6 25 27  1  1 25 31  4 31 18  2 37  4 31  6 18
 20 31 28 31 34  2 18 33 15 11  9 16 25 15 31  6 14 19 31 31 31 11 24 34
 21 32 15  4 12 34 31 31 16  4 20 25 20 37 27 18  5  4 24 25 16 17 24 31
 13  2 31 19  8 27 10 34 36 15 18 15 11 20 31 18  8  4 19 19  1  1 32 17
 34 20 18 31 16 12 18 15  2 18 31 18  1 31 20 20 25  5 31 34  9 31  1  1
 24 31  2 31  4 15 31 27 18 18  6 17 31 29 17 38 30 16 31  3 31 21 20 11
 34 12 30 25  4 24  2 25  5 31 11  2 15 18 31  4  6 31 36 14  0  7 30 19
 39 31  1 12 19  6 12 17 36 18 20 31 27 39 18  0  4  2 12 23 39 10 31 16
 12  4 31 14 31 31  6 32 31 36 34 19  6  6 11 31  9 39 15 14 20  2 22 16
 17  2  0 20  2  0 12  8  9 34 31 27 31 14  0 18  4 25  2 19  0 22 22  4
 20 36 16  8 11 13 25  1 10 31 31 34 31 19 25 16 17  2 31 25  8  2 31  8
 34 25 13 12  6 21  1 35 20 20  6 31 31  0  1 16 31 27 31 29 31 34  8  2
 36 20 16 19 16 25 12 11  1 16 31 16 15 31 27 32 31  1  8 19 31 36  4 31
 15 31 19 32 31 37 12  4  5 18 25]
2024-01-18 10:36:06,620 [l2p_self_training.py] => 2365 unlabeled samples will be pseudo labeled
2024-01-18 10:36:06,620 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:36:06,621 [toolkit.py] => Pseudo Accuracy: 0.8228329809725159
2024-01-18 10:36:06,628 [l2p_self_training.py] => train dataset length: 2615
Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30: 100%|██████████████████████████████████████████████████| 5/5 [02:22<00:00, 28.53s/it]
2024-01-18 10:38:29,292 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.035, Train_accy 91.13, Test_accy 32.30
2024-01-18 10:38:29,294 [l2p_self_training.py] => pseudo labeling start
2024-01-18 10:38:48,465 [l2p_self_training.py] => wrong labeled samples' pseudo label:
[30 35 30 30 30 38 30 39 39 39 38 39 36 39 30 30 39 39 30 31 30 30 38 35
 32 30 38 39 30 30 38 35 30 39 39 30 30 37 30 30 38 35 37 30 38 30 33 35
 28 30 39 30 30 30 38 36 38 35 32 33 35 39 35 39 33 39 30 30 30 35 37 37
 39 30 36 39 37 38 35 38 35 32 30 38 32 30 30 30 30 30 38 39 38 38 37 38
 30 39 32 31 35 38 35 33 35 33 39 39 39 35 30 32 39 38 35 30 34 30 30 35
 32 38 30 30 35 35 30 35 35 30 36 30 32 35 35 30 39 35 30 38 39 37 30 30
 39 39 30 37 39 30 30 35 30 39 30 39 35 30 37 38 39 35 30 30 32 39 30 39
 30 39 35 35 35 28 39 30 30 32 39 35 38 30 38 35 39 30 39 39 35 33 35 39
 38 39 30 30 39 36 32 30 30 39 39 35 33 30 28 30 33 38 30 30 38 38 38 39
 34 30 39 30 30 30 35 30 30 30 30 39 39 30 32 33 39 37 39 30 32 30 35 30
 38 31 35 37 35 38 38 30 37 36 39 30 32 39 33 30 38 35 38 37 30 38 30 32
 30 39 38 30 32 39 37 39 33 39 32 30 35 35 32 39 33 38 36 38 30 30 37 38
 33 35 38 30 33 35 30 30 37 30 31 30 30 30 35 30 30 30 37 38 38 30 30 35
 30 39 32 39 30 37 38 35 35 32 38 30 39 39 39 39 38 33 38 35 30 37 39 35
 39 38 35 30 30 36 33 30 37 39 30 35 34 30 37 30 39 32 35 38 30 30 38 39
 30 30 39 35 35 39 32 35 35 38 32 39 31 38 35 30 39 30 39 30 30 39 35 39
 30 33 37 38 30 30 35 35 39 30 30 39 30 36 33 35 30 38 35 37 30 30 38 37
 35 37 35 30 35 30 30 37 30 39 38 35 30 28 38 30 36 37 38 37 30 39 39 30
 35 37 39 39 33 38 39 38 38 36 30 35 30 35 30 30 37 33 30 35 33 30 38 39
 30 39 37 30 33 30 30 30 39 37 38 38 39 33 35 30 38 39 30 37 35 38 38 30
 30 35 31 38 35 35 30 36 30 30 39 39 30 33]
2024-01-18 10:38:48,467 [l2p_self_training.py] => wrong labeled samples' true label:
[11 31 31 11 31 18  5 14 27 19 18 27 32 22 31 20 27 12 11  6 20 31 35  0
 16 24 18 17 31 31 12  0 20 19  2 31 10 15 10  0 19  1 31 20 18 20 34  1
 10 31 27 31 31 31 12 21 12  4 16 34 36 27  4  2 34 32 31  3 31 38 15 31
 14 31 33 17 15 14  1  5  0 16 31 17 16 31 31 31 31 20 25 35 14 18 15 34
 24 22 16  6  4 25  1 34 31 13 17 19  8  0 31 16  2 12 26 24 16 31 31  4
 35 25 20 31  0  4 31  1  9  5 28 31 16  0  1 31 17 30 31 18  2 15 31  6
 27 23 31 15 12 20 31  4 31  7 31  8  1 11 10 12  2  0 11 31 16 17 24  8
 31  7  4  1  9 10  8 31  9 27 27  4  5 20 25 36 14 31  2  2  4 13  4  8
 25  2 31 31 27 33 14 31 20 34 22  1 34 31 10 31 13 18 31 24 25 25 12 19
 22 10  8 20  6 24  4 31 20 31 31 22  2 31 35 13  2 31  2 31 39 11  9 11
 18  6  1 15  4 25 18 31 15 29 38 31  8 27 34 31 18  1 12 15 31 25 31  2
 20 23 18 20 16 27 15 17 34  2 36 31 31  1 34 32 13 19 34 12 31  9 15 12
 13  0 34 11 13  4 31 20 36 31  6 31 31 31  1 31 11 31 15 18 19 31 31  9
 31  8 16  8 31 36 18  4 31 16 12 11 34  2 38  3 25 21 18  1 31 15  2  0
 17 25  0 20 24 13 34 31 31 19 24  1 15 24 32 31 16 37  0 18 31 24 25  7
  5 20 27  0  4 17 16  4  0 25 34  8  5 25  0 31  7 31  8 20 20 17  0  2
 31 13  7 25 11 31  1 30 16 31 24  2 31 29 13 33 20 25  1 39 31  6 25 15
 21 15  1  6  9  3 31 15 31 19 18  3 11 37 18 31 13 32 18  5 31 19 19  6
  4 15 27 27 13 25 14  7 12 29 31  0 31  0 31 31 28 21  6 17 21 31 12 14
 11  8  3 11 34 31 11 11 17 15 14 18 12 13  1  6 39 16 31 15  4 30 18 31
 31  4  6 18  1  9 20 29 20 35 17 19 31 36]
2024-01-18 10:38:48,468 [l2p_self_training.py] => 2407 unlabeled samples will be pseudo labeled
2024-01-18 10:38:48,468 [l2p_self_training.py] => pseudo labeling finish
2024-01-18 10:38:48,469 [toolkit.py] => Pseudo Accuracy: 0.7947652679684254
2024-01-18 10:39:11,851 [trainer.py] => No NME accuracy.
2024-01-18 10:39:11,851 [trainer.py] => CNN: {'total': 32.3, '00-09': 0.0, '10-19': 0.0, '20-29': 39.6, '30-39': 89.6, 'old': 13.2, 'new': 89.6}
2024-01-18 10:39:11,851 [trainer.py] => CNN top1 curve: [90.7, 48.5, 31.97, 32.3]
2024-01-18 10:39:11,851 [trainer.py] => CNN top5 curve: [99.2, 54.8, 42.0, 39.83]

Average Accuracy (CNN): 50.86749999999999
2024-01-18 10:39:11,851 [trainer.py] => Average Accuracy (CNN): 50.86749999999999


######################################################################################
======================================================================================
######################################################################################

(base) root@autodl-container-56644e8033-177721e5:~/autodl-tmp/LAMDA-PILOT# python main.py --config=./exps/l2p_self_training.json
2024-01-24 17:14:07,657 [trainer.py] => config: ./exps/l2p_self_training.json
2024-01-24 17:14:07,657 [trainer.py] => prefix:  
2024-01-24 17:14:07,657 [trainer.py] => dataset: cifar224
2024-01-24 17:14:07,657 [trainer.py] => memory_size: 0
2024-01-24 17:14:07,657 [trainer.py] => memory_per_class: 0
2024-01-24 17:14:07,657 [trainer.py] => fixed_memory: False
2024-01-24 17:14:07,657 [trainer.py] => shuffle: True
2024-01-24 17:14:07,657 [trainer.py] => init_cls: 10
2024-01-24 17:14:07,657 [trainer.py] => increment: 10
2024-01-24 17:14:07,657 [trainer.py] => model_name: l2p_self_training
2024-01-24 17:14:07,657 [trainer.py] => backbone_type: vit_base_patch16_224_l2p
2024-01-24 17:14:07,657 [trainer.py] => get_original_backbone: True
2024-01-24 17:14:07,657 [trainer.py] => device: [device(type='cuda', index=0)]
2024-01-24 17:14:07,657 [trainer.py] => seed: 1993
2024-01-24 17:14:07,657 [trainer.py] => tuned_epoch: 5
2024-01-24 17:14:07,657 [trainer.py] => init_lr: 0.001875
2024-01-24 17:14:07,657 [trainer.py] => batch_size: 16
2024-01-24 17:14:07,657 [trainer.py] => weight_decay: 0
2024-01-24 17:14:07,657 [trainer.py] => min_lr: 1e-05
2024-01-24 17:14:07,657 [trainer.py] => optimizer: adam
2024-01-24 17:14:07,657 [trainer.py] => scheduler: constant
2024-01-24 17:14:07,658 [trainer.py] => reinit_optimizer: True
2024-01-24 17:14:07,658 [trainer.py] => global_pool: token
2024-01-24 17:14:07,658 [trainer.py] => head_type: prompt
2024-01-24 17:14:07,658 [trainer.py] => freeze: ['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed']
2024-01-24 17:14:07,658 [trainer.py] => pretrained: True
2024-01-24 17:14:07,658 [trainer.py] => drop: 0.0
2024-01-24 17:14:07,658 [trainer.py] => drop_path: 0.0
2024-01-24 17:14:07,658 [trainer.py] => prompt_pool: True
2024-01-24 17:14:07,658 [trainer.py] => pool_size: 10
2024-01-24 17:14:07,658 [trainer.py] => length: 5
2024-01-24 17:14:07,658 [trainer.py] => top_k: 5
2024-01-24 17:14:07,658 [trainer.py] => initializer: uniform
2024-01-24 17:14:07,658 [trainer.py] => prompt_key: True
2024-01-24 17:14:07,658 [trainer.py] => prompt_key_init: uniform
2024-01-24 17:14:07,658 [trainer.py] => use_prompt_mask: False
2024-01-24 17:14:07,658 [trainer.py] => shared_prompt_pool: False
2024-01-24 17:14:07,658 [trainer.py] => shared_prompt_key: False
2024-01-24 17:14:07,658 [trainer.py] => batchwise_prompt: True
2024-01-24 17:14:07,658 [trainer.py] => embedding_key: cls
2024-01-24 17:14:07,658 [trainer.py] => predefined_key: 
2024-01-24 17:14:07,658 [trainer.py] => pull_constraint: True
2024-01-24 17:14:07,658 [trainer.py] => pull_constraint_coeff: 0.1
2024-01-24 17:14:07,658 [trainer.py] => semi_supervised_mode: True
2024-01-24 17:14:07,658 [trainer.py] => labeled_ratio: 0.05
2024-01-24 17:14:07,658 [trainer.py] => unlabeled_data_distribution_mode: previous_oot
2024-01-24 17:14:07,658 [trainer.py] => confidence_threshold: 0.9
2024-01-24 17:14:07,658 [trainer.py] => max_self_training_iteration: 3
Files already downloaded and verified
Files already downloaded and verified
2024-01-24 17:14:09,211 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2024-01-24 17:14:10,767 [vision_transformer_l2p.py] => Resized position embedding: torch.Size([1, 197, 768]) to torch.Size([1, 222, 768])
2024-01-24 17:14:10,768 [vision_transformer_l2p.py] => Position embedding grid-size from [14, 14] to (14, 14)
2024-01-24 17:14:13,139 [l2p_self_training.py] => 85,940,836 model total parameters.
2024-01-24 17:14:13,139 [l2p_self_training.py] => 122,980 model training parameters.
2024-01-24 17:14:13,139 [l2p_self_training.py] => prompt.prompt: 38400
2024-01-24 17:14:13,139 [l2p_self_training.py] => prompt.prompt_key: 7680
2024-01-24 17:14:13,140 [l2p_self_training.py] => head.weight: 76800
2024-01-24 17:14:13,140 [l2p_self_training.py] => head.bias: 100
2024-01-24 17:14:13,141 [trainer.py] => All params: 171816392
2024-01-24 17:14:13,142 [trainer.py] => Trainable params: 122980
2024-01-24 17:14:13,142 [l2p_self_training.py] => Learning on 0-10
2024-01-24 17:14:13,448 [l2p_self_training.py] => train dataset length: 250
Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50: 100%|████████████████████████████████████████████████████████████████████| 5/5 [00:11<00:00,  2.32s/it]
2024-01-24 17:14:25,061 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 0 => Loss 0.515, Train_accy 84.00, Test_accy 89.50
2024-01-24 17:14:25,068 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:14:33,170 [l2p_self_training.py] => 1038 unlabeled samples will be pseudo labeled
2024-01-24 17:14:33,170 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:14:33,171 [toolkit.py] => Pseudo Accuracy: 0.9788053949903661
2024-01-24 17:14:33,176 [l2p_self_training.py] => train dataset length: 1288
Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70: 100%|████████████████████████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.31s/it]
2024-01-24 17:15:09,720 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.137, Train_accy 90.99, Test_accy 92.70
2024-01-24 17:15:09,727 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:15:17,619 [l2p_self_training.py] => 1668 unlabeled samples will be pseudo labeled
2024-01-24 17:15:17,620 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:15:17,620 [toolkit.py] => Pseudo Accuracy: 0.9508393285371702
2024-01-24 17:15:17,629 [l2p_self_training.py] => train dataset length: 1918
Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70: 100%|████████████████████████████████████████████████████████████████████| 5/5 [00:50<00:00, 10.05s/it]
2024-01-24 17:16:07,861 [l2p_self_training.py] => Task 0, Epoch 5/5, Self_training_Iteration: 2 => Loss 0.061, Train_accy 88.74, Test_accy 90.70
2024-01-24 17:16:07,868 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:16:15,798 [l2p_self_training.py] => 1679 unlabeled samples will be pseudo labeled
2024-01-24 17:16:15,799 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:16:15,799 [toolkit.py] => Pseudo Accuracy: 0.9535437760571769
2024-01-24 17:16:19,293 [trainer.py] => No NME accuracy.
2024-01-24 17:16:19,294 [trainer.py] => CNN: {'total': 90.7, '00-09': 90.7, 'old': 0, 'new': 90.7}
2024-01-24 17:16:19,294 [trainer.py] => CNN top1 curve: [90.7]
2024-01-24 17:16:19,294 [trainer.py] => CNN top5 curve: [99.2]

Average Accuracy (CNN): 90.7
2024-01-24 17:16:19,294 [trainer.py] => Average Accuracy (CNN): 90.7 

2024-01-24 17:16:19,299 [trainer.py] => All params: 171816392
2024-01-24 17:16:19,302 [trainer.py] => Trainable params: 122980
2024-01-24 17:16:19,302 [l2p_self_training.py] => Learning on 10-20
2024-01-24 17:16:19,344 [l2p_self_training.py] => train dataset length: 250
Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.008, Train_accy 90.80, Test_accy 80.30: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:15<00:00,  3.10s/it]
2024-01-24 17:16:34,852 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.008, Train_accy 90.80, Test_accy 80.30
2024-01-24 17:16:34,858 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:16:43,802 [l2p_self_training.py] => 1567 unlabeled samples will be pseudo labeled
2024-01-24 17:16:43,802 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:16:43,802 [toolkit.py] => Pseudo Accuracy: 0.9578813018506701
2024-01-24 17:16:43,805 [l2p_self_training.py] => train dataset length: 1817
Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.051, Train_accy 88.99, Test_accy 86.45: 100%|████████████████████████████████████████████████████████████████████| 5/5 [00:51<00:00, 10.38s/it]
2024-01-24 17:17:35,705 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 1 => Loss 0.051, Train_accy 88.99, Test_accy 86.45
2024-01-24 17:17:35,712 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:17:44,610 [l2p_self_training.py] => 1843 unlabeled samples will be pseudo labeled
2024-01-24 17:17:44,611 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:17:44,611 [toolkit.py] => Pseudo Accuracy: 0.9289202387411829
2024-01-24 17:17:44,617 [l2p_self_training.py] => train dataset length: 2093
Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.008, Train_accy 89.73, Test_accy 79.45: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:58<00:00, 11.66s/it]
2024-01-24 17:18:42,895 [l2p_self_training.py] => Task 1, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.008, Train_accy 89.73, Test_accy 79.45
2024-01-24 17:18:42,900 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:18:51,740 [l2p_self_training.py] => 1978 unlabeled samples will be pseudo labeled
2024-01-24 17:18:51,740 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:18:51,740 [toolkit.py] => Pseudo Accuracy: 0.89737108190091
2024-01-24 17:18:58,456 [trainer.py] => No NME accuracy.
2024-01-24 17:18:58,456 [trainer.py] => CNN: {'total': 79.45, '00-09': 69.0, '10-19': 89.9, 'old': 69.0, 'new': 89.9}
2024-01-24 17:18:58,456 [trainer.py] => CNN top1 curve: [90.7, 79.45]
2024-01-24 17:18:58,457 [trainer.py] => CNN top5 curve: [99.2, 97.95]

Average Accuracy (CNN): 85.075
2024-01-24 17:18:58,457 [trainer.py] => Average Accuracy (CNN): 85.075 

2024-01-24 17:18:58,462 [trainer.py] => All params: 171816392
2024-01-24 17:18:58,465 [trainer.py] => Trainable params: 122980
2024-01-24 17:18:58,465 [l2p_self_training.py] => Learning on 20-30
2024-01-24 17:18:58,505 [l2p_self_training.py] => train dataset length: 250
Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.118, Train_accy 93.20, Test_accy 71.40: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.71s/it]
2024-01-24 17:19:17,037 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.118, Train_accy 93.20, Test_accy 71.40
2024-01-24 17:19:17,044 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:19:26,691 [l2p_self_training.py] => 1936 unlabeled samples will be pseudo labeled
2024-01-24 17:19:26,693 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:19:26,694 [toolkit.py] => Pseudo Accuracy: 0.952995867768595
2024-01-24 17:19:26,705 [l2p_self_training.py] => train dataset length: 2186
Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.090, Train_accy 93.37, Test_accy 80.53: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:02<00:00, 12.51s/it]
2024-01-24 17:20:29,264 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.090, Train_accy 93.37, Test_accy 80.53
2024-01-24 17:20:29,271 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:20:38,733 [l2p_self_training.py] => 2281 unlabeled samples will be pseudo labeled
2024-01-24 17:20:38,734 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:20:38,734 [toolkit.py] => Pseudo Accuracy: 0.8991670320035072
2024-01-24 17:20:38,752 [l2p_self_training.py] => train dataset length: 2531
Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.080, Train_accy 92.45, Test_accy 76.67: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:10<00:00, 14.16s/it]
2024-01-24 17:21:49,555 [l2p_self_training.py] => Task 2, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.080, Train_accy 92.45, Test_accy 76.67
2024-01-24 17:21:49,562 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:21:59,072 [l2p_self_training.py] => 2319 unlabeled samples will be pseudo labeled
2024-01-24 17:21:59,073 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:21:59,073 [toolkit.py] => Pseudo Accuracy: 0.8831392841742131
2024-01-24 17:22:08,634 [trainer.py] => No NME accuracy.
2024-01-24 17:22:08,635 [trainer.py] => CNN: {'total': 76.67, '00-09': 58.3, '10-19': 82.8, '20-29': 88.9, 'old': 70.55, 'new': 88.9}
2024-01-24 17:22:08,635 [trainer.py] => CNN top1 curve: [90.7, 79.45, 76.67]
2024-01-24 17:22:08,635 [trainer.py] => CNN top5 curve: [99.2, 97.95, 97.53]

Average Accuracy (CNN): 82.27333333333333
2024-01-24 17:22:08,635 [trainer.py] => Average Accuracy (CNN): 82.27333333333333 

2024-01-24 17:22:08,640 [trainer.py] => All params: 171816392
2024-01-24 17:22:08,643 [trainer.py] => Trainable params: 122980
2024-01-24 17:22:08,643 [l2p_self_training.py] => Learning on 30-40
2024-01-24 17:22:08,688 [l2p_self_training.py] => train dataset length: 250
Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.101, Train_accy 94.00, Test_accy 70.75: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:21<00:00,  4.27s/it]
2024-01-24 17:22:30,038 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.101, Train_accy 94.00, Test_accy 70.75
2024-01-24 17:22:30,044 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:22:40,276 [l2p_self_training.py] => 1885 unlabeled samples will be pseudo labeled
2024-01-24 17:22:40,276 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:22:40,277 [toolkit.py] => Pseudo Accuracy: 0.9013262599469496
2024-01-24 17:22:40,284 [l2p_self_training.py] => train dataset length: 2135
Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.65, Test_accy 74.75: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:04<00:00, 12.88s/it]
2024-01-24 17:23:44,706 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.099, Train_accy 92.65, Test_accy 74.75
2024-01-24 17:23:44,713 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:23:54,902 [l2p_self_training.py] => 2350 unlabeled samples will be pseudo labeled
2024-01-24 17:23:54,902 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:23:54,903 [toolkit.py] => Pseudo Accuracy: 0.8204255319148936
2024-01-24 17:23:54,913 [l2p_self_training.py] => train dataset length: 2600
Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.026, Train_accy 91.23, Test_accy 74.15: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:15<00:00, 15.03s/it]
2024-01-24 17:25:10,067 [l2p_self_training.py] => Task 3, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.026, Train_accy 91.23, Test_accy 74.15
2024-01-24 17:25:10,072 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:25:20,377 [l2p_self_training.py] => 2245 unlabeled samples will be pseudo labeled
2024-01-24 17:25:20,378 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:25:20,378 [toolkit.py] => Pseudo Accuracy: 0.7964365256124721
2024-01-24 17:25:32,987 [trainer.py] => No NME accuracy.
2024-01-24 17:25:32,987 [trainer.py] => CNN: {'total': 74.15, '00-09': 53.6, '10-19': 78.7, '20-29': 86.7, '30-39': 77.6, 'old': 73.0, 'new': 77.6}
2024-01-24 17:25:32,988 [trainer.py] => CNN top1 curve: [90.7, 79.45, 76.67, 74.15]
2024-01-24 17:25:32,988 [trainer.py] => CNN top5 curve: [99.2, 97.95, 97.53, 96.02]

Average Accuracy (CNN): 80.2425
2024-01-24 17:25:32,988 [trainer.py] => Average Accuracy (CNN): 80.2425 

2024-01-24 17:25:32,991 [trainer.py] => All params: 171816392
2024-01-24 17:25:32,994 [trainer.py] => Trainable params: 122980
2024-01-24 17:25:32,994 [l2p_self_training.py] => Learning on 40-50
2024-01-24 17:25:33,046 [l2p_self_training.py] => train dataset length: 250
Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.125, Train_accy 93.20, Test_accy 69.48: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:25<00:00,  5.03s/it]
2024-01-24 17:25:58,200 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.125, Train_accy 93.20, Test_accy 69.48
2024-01-24 17:25:58,206 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:26:09,339 [l2p_self_training.py] => 2113 unlabeled samples will be pseudo labeled
2024-01-24 17:26:09,340 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:26:09,340 [toolkit.py] => Pseudo Accuracy: 0.8864174159962139
2024-01-24 17:26:09,346 [l2p_self_training.py] => train dataset length: 2363
Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.121, Train_accy 93.78, Test_accy 75.38: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:12<00:00, 14.52s/it]
2024-01-24 17:27:21,949 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.121, Train_accy 93.78, Test_accy 75.38
2024-01-24 17:27:21,956 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:27:33,096 [l2p_self_training.py] => 2644 unlabeled samples will be pseudo labeled
2024-01-24 17:27:33,097 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:27:33,098 [toolkit.py] => Pseudo Accuracy: 0.7946293494704992
2024-01-24 17:27:33,105 [l2p_self_training.py] => train dataset length: 2894
Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.050, Train_accy 91.85, Test_accy 69.44: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:25<00:00, 17.13s/it]
2024-01-24 17:28:58,780 [l2p_self_training.py] => Task 4, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.050, Train_accy 91.85, Test_accy 69.44
2024-01-24 17:28:58,787 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:29:10,041 [l2p_self_training.py] => 2643 unlabeled samples will be pseudo labeled
2024-01-24 17:29:10,041 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:29:10,042 [toolkit.py] => Pseudo Accuracy: 0.7529322739311388
2024-01-24 17:29:25,611 [trainer.py] => No NME accuracy.
2024-01-24 17:29:25,612 [trainer.py] => CNN: {'total': 69.44, '00-09': 48.2, '10-19': 68.6, '20-29': 77.5, '30-39': 73.9, '40-49': 79.0, 'old': 67.05, 'new': 79.0}
2024-01-24 17:29:25,612 [trainer.py] => CNN top1 curve: [90.7, 79.45, 76.67, 74.15, 69.44]
2024-01-24 17:29:25,612 [trainer.py] => CNN top5 curve: [99.2, 97.95, 97.53, 96.02, 95.26]

Average Accuracy (CNN): 78.08200000000001
2024-01-24 17:29:25,613 [trainer.py] => Average Accuracy (CNN): 78.08200000000001 

2024-01-24 17:29:25,616 [trainer.py] => All params: 171816392
2024-01-24 17:29:25,619 [trainer.py] => Trainable params: 122980
2024-01-24 17:29:25,619 [l2p_self_training.py] => Learning on 50-60
2024-01-24 17:29:25,677 [l2p_self_training.py] => train dataset length: 250
Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.076, Train_accy 89.60, Test_accy 66.85: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:27<00:00,  5.58s/it]
2024-01-24 17:29:53,581 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.076, Train_accy 89.60, Test_accy 66.85
2024-01-24 17:29:53,587 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:30:05,296 [l2p_self_training.py] => 1955 unlabeled samples will be pseudo labeled
2024-01-24 17:30:05,297 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:30:05,298 [toolkit.py] => Pseudo Accuracy: 0.8838874680306905
2024-01-24 17:30:05,303 [l2p_self_training.py] => train dataset length: 2205
Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.140, Train_accy 94.01, Test_accy 69.83: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:12<00:00, 14.51s/it]
2024-01-24 17:31:17,865 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.140, Train_accy 94.01, Test_accy 69.83
2024-01-24 17:31:17,871 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:31:29,764 [l2p_self_training.py] => 2532 unlabeled samples will be pseudo labeled
2024-01-24 17:31:29,765 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:31:29,766 [toolkit.py] => Pseudo Accuracy: 0.7571090047393365
2024-01-24 17:31:29,773 [l2p_self_training.py] => train dataset length: 2782
Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.038, Train_accy 91.12, Test_accy 67.72: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:26<00:00, 17.27s/it]
2024-01-24 17:32:56,123 [l2p_self_training.py] => Task 5, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.038, Train_accy 91.12, Test_accy 67.72
2024-01-24 17:32:56,129 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:33:07,932 [l2p_self_training.py] => 2529 unlabeled samples will be pseudo labeled
2024-01-24 17:33:07,933 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:33:07,934 [toolkit.py] => Pseudo Accuracy: 0.730328192961645
2024-01-24 17:33:26,472 [trainer.py] => No NME accuracy.
2024-01-24 17:33:26,472 [trainer.py] => CNN: {'total': 67.72, '00-09': 40.4, '10-19': 68.3, '20-29': 67.1, '30-39': 71.6, '40-49': 75.5, '50-59': 83.4, 'old': 64.58, 'new': 83.4}
2024-01-24 17:33:26,472 [trainer.py] => CNN top1 curve: [90.7, 79.45, 76.67, 74.15, 69.44, 67.72]
2024-01-24 17:33:26,472 [trainer.py] => CNN top5 curve: [99.2, 97.95, 97.53, 96.02, 95.26, 94.62]

Average Accuracy (CNN): 76.355
2024-01-24 17:33:26,472 [trainer.py] => Average Accuracy (CNN): 76.355 

2024-01-24 17:33:26,476 [trainer.py] => All params: 171816392
2024-01-24 17:33:26,478 [trainer.py] => Trainable params: 122980
2024-01-24 17:33:26,478 [l2p_self_training.py] => Learning on 60-70
2024-01-24 17:33:26,538 [l2p_self_training.py] => train dataset length: 250
Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.131, Train_accy 93.20, Test_accy 67.41: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:30<00:00,  6.03s/it]
2024-01-24 17:33:56,675 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.131, Train_accy 93.20, Test_accy 67.41
2024-01-24 17:33:56,681 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:34:09,281 [l2p_self_training.py] => 2098 unlabeled samples will be pseudo labeled
2024-01-24 17:34:09,281 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:34:09,282 [toolkit.py] => Pseudo Accuracy: 0.9223069590085796
2024-01-24 17:34:09,288 [l2p_self_training.py] => train dataset length: 2348
Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.152, Train_accy 94.72, Test_accy 69.13: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:18<00:00, 15.79s/it]
2024-01-24 17:35:28,243 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.152, Train_accy 94.72, Test_accy 69.13
2024-01-24 17:35:28,249 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:35:40,761 [l2p_self_training.py] => 2793 unlabeled samples will be pseudo labeled
2024-01-24 17:35:40,761 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:35:40,762 [toolkit.py] => Pseudo Accuracy: 0.7715717866093806
2024-01-24 17:35:40,770 [l2p_self_training.py] => train dataset length: 3043
Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.102, Train_accy 93.00, Test_accy 66.91: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:34<00:00, 18.96s/it]
2024-01-24 17:37:15,577 [l2p_self_training.py] => Task 6, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.102, Train_accy 93.00, Test_accy 66.91
2024-01-24 17:37:15,584 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:37:28,319 [l2p_self_training.py] => 2926 unlabeled samples will be pseudo labeled
2024-01-24 17:37:28,319 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:37:28,319 [toolkit.py] => Pseudo Accuracy: 0.7259056732740943
2024-01-24 17:37:50,006 [trainer.py] => No NME accuracy.
2024-01-24 17:37:50,007 [trainer.py] => CNN: {'total': 66.91, '00-09': 29.9, '10-19': 65.6, '20-29': 68.0, '30-39': 68.6, '40-49': 73.6, '50-59': 71.0, '60-69': 91.7, 'old': 62.78, 'new': 91.7}
2024-01-24 17:37:50,007 [trainer.py] => CNN top1 curve: [90.7, 79.45, 76.67, 74.15, 69.44, 67.72, 66.91]
2024-01-24 17:37:50,007 [trainer.py] => CNN top5 curve: [99.2, 97.95, 97.53, 96.02, 95.26, 94.62, 94.29]

Average Accuracy (CNN): 75.00571428571428
2024-01-24 17:37:50,007 [trainer.py] => Average Accuracy (CNN): 75.00571428571428 

2024-01-24 17:37:50,010 [trainer.py] => All params: 171816392
2024-01-24 17:37:50,013 [trainer.py] => Trainable params: 122980
2024-01-24 17:37:50,013 [l2p_self_training.py] => Learning on 70-80
2024-01-24 17:37:50,089 [l2p_self_training.py] => train dataset length: 250
Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.071, Train_accy 92.40, Test_accy 63.69: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:33<00:00,  6.71s/it]
2024-01-24 17:38:23,658 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.071, Train_accy 92.40, Test_accy 63.69
2024-01-24 17:38:23,660 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:38:36,878 [l2p_self_training.py] => 1959 unlabeled samples will be pseudo labeled
2024-01-24 17:38:36,878 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:38:36,879 [toolkit.py] => Pseudo Accuracy: 0.8249106687085248
2024-01-24 17:38:36,885 [l2p_self_training.py] => train dataset length: 2209
Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.172, Train_accy 95.20, Test_accy 65.60: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:18<00:00, 15.67s/it]
2024-01-24 17:39:55,213 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.172, Train_accy 95.20, Test_accy 65.60
2024-01-24 17:39:55,220 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:40:08,595 [l2p_self_training.py] => 2845 unlabeled samples will be pseudo labeled
2024-01-24 17:40:08,595 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:40:08,596 [toolkit.py] => Pseudo Accuracy: 0.680140597539543
2024-01-24 17:40:08,605 [l2p_self_training.py] => train dataset length: 3095
Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.060, Train_accy 91.76, Test_accy 62.65: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:39<00:00, 19.83s/it]
2024-01-24 17:41:47,745 [l2p_self_training.py] => Task 7, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.060, Train_accy 91.76, Test_accy 62.65
2024-01-24 17:41:47,752 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:42:00,927 [l2p_self_training.py] => 2849 unlabeled samples will be pseudo labeled
2024-01-24 17:42:00,927 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:42:00,928 [toolkit.py] => Pseudo Accuracy: 0.6493506493506493
2024-01-24 17:42:25,391 [trainer.py] => No NME accuracy.
2024-01-24 17:42:25,392 [trainer.py] => CNN: {'total': 62.65, '00-09': 24.8, '10-19': 60.8, '20-29': 64.6, '30-39': 67.3, '40-49': 69.3, '50-59': 62.7, '60-69': 86.3, '70-79': 65.4, 'old': 62.26, 'new': 65.4}
2024-01-24 17:42:25,392 [trainer.py] => CNN top1 curve: [90.7, 79.45, 76.67, 74.15, 69.44, 67.72, 66.91, 62.65]
2024-01-24 17:42:25,392 [trainer.py] => CNN top5 curve: [99.2, 97.95, 97.53, 96.02, 95.26, 94.62, 94.29, 92.76]

Average Accuracy (CNN): 73.46124999999999
2024-01-24 17:42:25,392 [trainer.py] => Average Accuracy (CNN): 73.46124999999999 

2024-01-24 17:42:25,395 [trainer.py] => All params: 171816392
2024-01-24 17:42:25,397 [trainer.py] => Trainable params: 122980
2024-01-24 17:42:25,398 [l2p_self_training.py] => Learning on 80-90
2024-01-24 17:42:25,480 [l2p_self_training.py] => train dataset length: 250
Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.080, Train_accy 91.60, Test_accy 59.66: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:36<00:00,  7.33s/it]
2024-01-24 17:43:02,107 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.080, Train_accy 91.60, Test_accy 59.66
2024-01-24 17:43:02,114 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:43:16,094 [l2p_self_training.py] => 2160 unlabeled samples will be pseudo labeled
2024-01-24 17:43:16,095 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:43:16,096 [toolkit.py] => Pseudo Accuracy: 0.8268518518518518
2024-01-24 17:43:16,108 [l2p_self_training.py] => train dataset length: 2410
Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.134, Train_accy 94.56, Test_accy 63.28: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:25<00:00, 17.11s/it]
2024-01-24 17:44:41,681 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.134, Train_accy 94.56, Test_accy 63.28
2024-01-24 17:44:41,688 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:44:55,659 [l2p_self_training.py] => 3007 unlabeled samples will be pseudo labeled
2024-01-24 17:44:55,660 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:44:55,661 [toolkit.py] => Pseudo Accuracy: 0.6677751912204856
2024-01-24 17:44:55,670 [l2p_self_training.py] => train dataset length: 3257
Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.097, Train_accy 93.28, Test_accy 59.29: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.19s/it]
2024-01-24 17:46:41,625 [l2p_self_training.py] => Task 8, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.097, Train_accy 93.28, Test_accy 59.29
2024-01-24 17:46:41,632 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:46:55,706 [l2p_self_training.py] => 3195 unlabeled samples will be pseudo labeled
2024-01-24 17:46:55,706 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:46:55,707 [toolkit.py] => Pseudo Accuracy: 0.6115805946791862
2024-01-24 17:47:23,382 [trainer.py] => No NME accuracy.
2024-01-24 17:47:23,382 [trainer.py] => CNN: {'total': 59.29, '00-09': 21.7, '10-19': 57.1, '20-29': 60.5, '30-39': 56.7, '40-49': 63.5, '50-59': 57.6, '60-69': 79.9, '70-79': 54.3, '80-89': 82.3, 'old': 56.41, 'new': 82.3}
2024-01-24 17:47:23,383 [trainer.py] => CNN top1 curve: [90.7, 79.45, 76.67, 74.15, 69.44, 67.72, 66.91, 62.65, 59.29]
2024-01-24 17:47:23,383 [trainer.py] => CNN top5 curve: [99.2, 97.95, 97.53, 96.02, 95.26, 94.62, 94.29, 92.76, 91.22]

Average Accuracy (CNN): 71.88666666666666
2024-01-24 17:47:23,383 [trainer.py] => Average Accuracy (CNN): 71.88666666666666 

2024-01-24 17:47:23,386 [trainer.py] => All params: 171816392
2024-01-24 17:47:23,388 [trainer.py] => Trainable params: 122980
2024-01-24 17:47:23,389 [l2p_self_training.py] => Learning on 90-100
2024-01-24 17:47:23,472 [l2p_self_training.py] => train dataset length: 250
Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.082, Train_accy 91.20, Test_accy 57.56: 100%|███████████████████████████████████████████████████████████████████| 5/5 [00:39<00:00,  7.92s/it]
2024-01-24 17:48:03,056 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 0 => Loss -0.082, Train_accy 91.20, Test_accy 57.56
2024-01-24 17:48:03,062 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:48:17,702 [l2p_self_training.py] => 2073 unlabeled samples will be pseudo labeled
2024-01-24 17:48:17,703 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:48:17,703 [toolkit.py] => Pseudo Accuracy: 0.8470815243608297
2024-01-24 17:48:17,712 [l2p_self_training.py] => train dataset length: 2323
Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.147, Train_accy 94.53, Test_accy 60.91: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:26<00:00, 17.33s/it]
2024-01-24 17:49:44,339 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 1 => Loss -0.147, Train_accy 94.53, Test_accy 60.91
2024-01-24 17:49:44,345 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:49:59,123 [l2p_self_training.py] => 2872 unlabeled samples will be pseudo labeled
2024-01-24 17:49:59,123 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:49:59,124 [toolkit.py] => Pseudo Accuracy: 0.6974233983286908
2024-01-24 17:49:59,138 [l2p_self_training.py] => train dataset length: 3122
Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.083, Train_accy 92.31, Test_accy 60.09: 100%|███████████████████████████████████████████████████████████████████| 5/5 [01:45<00:00, 21.05s/it]
2024-01-24 17:51:44,404 [l2p_self_training.py] => Task 9, Epoch 5/5, Self_training_Iteration: 2 => Loss -0.083, Train_accy 92.31, Test_accy 60.09
2024-01-24 17:51:44,407 [l2p_self_training.py] => pseudo labeling start
2024-01-24 17:51:59,191 [l2p_self_training.py] => 3143 unlabeled samples will be pseudo labeled
2024-01-24 17:51:59,191 [l2p_self_training.py] => pseudo labeling finish
2024-01-24 17:51:59,192 [toolkit.py] => Pseudo Accuracy: 0.6360165447025136
2024-01-24 17:52:29,776 [trainer.py] => No NME accuracy.
2024-01-24 17:52:29,776 [trainer.py] => CNN: {'total': 60.09, '00-09': 20.9, '10-19': 54.9, '20-29': 60.7, '30-39': 53.9, '40-49': 61.2, '50-59': 55.0, '60-69': 78.3, '70-79': 52.7, '80-89': 80.9, '90-99': 82.4, 'old': 57.61, 'new': 82.4}
2024-01-24 17:52:29,776 [trainer.py] => CNN top1 curve: [90.7, 79.45, 76.67, 74.15, 69.44, 67.72, 66.91, 62.65, 59.29, 60.09]
2024-01-24 17:52:29,776 [trainer.py] => CNN top5 curve: [99.2, 97.95, 97.53, 96.02, 95.26, 94.62, 94.29, 92.76, 91.22, 91.0]

Average Accuracy (CNN): 70.707
2024-01-24 17:52:29,777 [trainer.py] => Average Accuracy (CNN): 70.707 