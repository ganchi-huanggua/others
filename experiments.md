## 实验

问题1：self-training和prompt到底可否结合产生更好的效果（待解决）



问题2：为什么在跨task的时候会产生loss=inf的情况，新任务的类会渐渐只预测成一个，比如10~19类最后只会预测出13类，其余的类预测数量都为0，而且旧任务的类精度会集体下降。而且跨task的第一次pseudo label的准确度并不低，可以达到99%

问题2-1：是伪标签打错了1%造成的吗

问题2-2：是跨任务的时候之前的self-training造成的吗



为解决问题2-1：在每次pseudo label后，剔除标签打错的数据，只把打对伪标签的数据进行self-training

实验结果：测试精度高于目前已知的所有方法。伪标签精度在task 1上表现正常，在task 2上的iter 1上掉到50%，随着iter增加最后提到70%。此后每个task的伪标签精度也就是这个趋势



为解决问题2-2：在第一个task上不做self-training，从第二个task下开始self-training

实验结果：task 1的测试精度正常，task 2的iter 1正常，iter 2时仍正常，但是loss变为infinite，iter 3后崩了。task 2的iter 1的pseudo label准确率为0.98655，iter 2时仍有0.97往上，但是iter 3后变为0，所有的标签全部被预测成了task 1上的10类



分析方法2-1、2-2：在task 1上做self-training后，task 2的iter 1上的伪标签准确率就崩，如果在task 1上不做self-training而直接在task 2上做Self-Training，则伪标签准确率能达到很高的水平。task 2的iter 1打的伪标签准确率很高了已经，但是为什么这么高准确率的数据做self-triaining后会使测试精度暴跌，最后只会预测task 1上的数据呢

衍生问题3：是否在同一个task上的数据训练太多次（iter 5 * epoch 5），然后再训练其他task上的数据是不是很难做到直接迁移，即用少量的有标签数据训练一轮就完成了类泛化（和问题1有相似的地方）

衍生问题4：导致测试精度暴跌的原因到底是不是那1%打错的脏数据（可能连20条都不到），在方法2-1上已经试过，如无噪声标签，实验是可以正常运行的



为解决问题3：



为解决问题4：1. 将方法2-1和方法2-2结合，即task 1不做self-training，task 2开始做Self-Training并剔除标签打错的数据，只把打对伪标签的数据进行self-training；2. 在上述方法的基础上，故意在task 2的self-training时加入几十个噪声标签，标签为新旧task的标签

实验结果：伪标签精度完全正常，但是每一轮iter的测试精度在下降，而且下降的都是task 2上的精度，task 1上的数据依然很准。加了新task标签的噪声数据后，实验结果和原方法基本一致，但是加了旧task标签的噪声数据后，产生了和方法2-2相似的实验结果。



分析方法4：我认定，之所以崩了的原因时在于伪标签打错的部分噪声数据，而且专指于打成旧任务标签的噪声数据，新任务标签的噪声数据对当前任务学习是基本不产生影响的。问题2、问题4得到解决

衍生问题5：为什么就几条旧任务标签的噪声数据会对新任务学习造成如此毁灭性的打击（不急解决了）



### oot问题

#### 问题基本设定

我们遵守并扩展增量学习问题范式：每个task来一部分有标签类，模型需要对这些有标签类进行泛化。task 1来1-10类的有标签，task 2来11-20类的有标签，以此类推。在此基础上，每个task也会有很多无标签数据，这些无标签数据既有当前task上10类，也有已经学过的旧task里的类、还未见过的新task里的类。

我们先对问题进行简化，只有旧task上的类，未见过的新task上的类数据不会参与当前类的训练。

#### 数据集构建

如下切分cifar100数据集，一个类有500个训练样本，先划分出5%，也就是25个有标签样本作为增量学习训练的部分。然后在分出250个作为无标签样本，和有标签样本一同在同一个task下。最后将剩下的225个样本分为9份，每一份25个样本，掺在非当前的类学习的剩下的9个task中。对每一类均是如此。这样，对于每一个task要学习的类，其中有25个有标签当前类样本，250个无标签当前类样本，之前task下的所有类的部分样本，每一类有25个。所以总训练数据是越来越多的，task t比task t-1多了10*25个样本。
